{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling (LDA) of NTSB Aviation Accident Narratives\n",
    "\n",
    "**Objective**: Discover latent topics in 67,126 aviation accident narratives using Latent Dirichlet Allocation (LDA) topic modeling.\n",
    "\n",
    "**Dataset**: NTSB Aviation Accident Database (1977-2025, 48 years)\n",
    "\n",
    "**Methods**:\n",
    "- Latent Dirichlet Allocation (LDA) with Gensim\n",
    "- Coherence score optimization (5-20 topics)\n",
    "- Topic word distributions and probabilities\n",
    "- Topic prevalence over time\n",
    "- Topic correlation with fatal outcomes\n",
    "\n",
    "**Author**: Claude Code (Anthropic)\n",
    "\n",
    "**Date**: 2025-11-08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import re\n",
    "import warnings\n",
    "from typing import List, Dict, Tuple\n",
    "import pickle\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Gensim imports\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "np.random.seed(42)\n",
    "\n",
    "print('‚úÖ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load narrative dataset\n",
    "df = pd.read_parquet('../../data/narratives_dataset.parquet')\n",
    "\n",
    "print(f'Dataset: {len(df):,} narrative records')\n",
    "print(f'Date range: {df[\"ev_year\"].min()} - {df[\"ev_year\"].max()}')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_lda(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocess text for LDA topic modeling.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw narrative text\n",
    "        \n",
    "    Returns:\n",
    "        List of cleaned tokens\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs and emails\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters (keep only letters)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Remove stopwords and short tokens\n",
    "    stop_words = set(STOPWORDS)\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 3]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Combine narratives and preprocess\n",
    "df['full_narrative'] = (df['narr_accp'].fillna('') + ' ' + df['narr_cause'].fillna('')).str.strip()\n",
    "df['tokens'] = df['full_narrative'].apply(preprocess_for_lda)\n",
    "\n",
    "# Remove empty documents\n",
    "df = df[df['tokens'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "# Add metadata\n",
    "df['fatal_outcome'] = df['inj_tot_f'] > 0\n",
    "df['decade'] = (df['ev_year'] // 10) * 10\n",
    "\n",
    "print(f'‚úÖ Preprocessed {len(df):,} narratives')\n",
    "print(f'Average tokens per narrative: {df[\"tokens\"].str.len().mean():.0f}')\n",
    "print(f'Median tokens per narrative: {df[\"tokens\"].str.len().median():.0f}')\n",
    "\n",
    "# Display example\n",
    "print('\\nExample tokenized narrative:')\n",
    "print(f'Original: {df[\"full_narrative\"].iloc[0][:200]}...')\n",
    "print(f'Tokens (first 30): {df[\"tokens\"].iloc[0][:30]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Dictionary and Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token lists\n",
    "texts = df['tokens'].tolist()\n",
    "\n",
    "# Create dictionary\n",
    "print('üîÑ Creating dictionary...')\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "print(f'Dictionary before filtering: {len(dictionary)} unique tokens')\n",
    "\n",
    "# Filter extremes\n",
    "dictionary.filter_extremes(\n",
    "    no_below=10,   # Minimum 10 documents\n",
    "    no_above=0.6,  # Maximum 60% of documents\n",
    "    keep_n=10000   # Keep top 10,000 tokens\n",
    ")\n",
    "\n",
    "print(f'Dictionary after filtering: {len(dictionary)} unique tokens')\n",
    "\n",
    "# Create corpus (bag-of-words)\n",
    "print('üîÑ Creating corpus...')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "print(f'‚úÖ Corpus created: {len(corpus):,} documents')\n",
    "print(f'Average tokens per document: {np.mean([len(doc) for doc in corpus]):.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determine Optimal Number of Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test different numbers of topics (full evaluation)\ntopic_range = [5, 10, 15, 20]  # Full range for comprehensive coherence testing\ncoherence_scores = []\n\nprint('üîÑ Testing different numbers of topics for coherence...\\n')\nprint('Note: Testing 4 topic counts (comprehensive evaluation)\\n')\n\nfor num_topics in topic_range:\n    print(f'Training LDA with {num_topics} topics...')\n    \n    lda_temp = LdaModel(\n        corpus=corpus,\n        id2word=dictionary,\n        num_topics=num_topics,\n        random_state=42,\n        passes=10,  # Full passes for comprehensive coherence testing\n        alpha='auto',\n        eta='auto',\n        per_word_topics=True\n    )\n    \n    # Compute coherence score\n    coherence_model = CoherenceModel(\n        model=lda_temp,\n        texts=texts,\n        dictionary=dictionary,\n        coherence='c_v'\n    )\n    coherence = coherence_model.get_coherence()\n    coherence_scores.append(coherence)\n    \n    print(f'  Coherence score: {coherence:.4f}\\n')\n\n# Find optimal number of topics\noptimal_idx = np.argmax(coherence_scores)\noptimal_topics = topic_range[optimal_idx]\noptimal_coherence = coherence_scores[optimal_idx]\n\nprint(f'\\n‚úÖ Optimal number of topics: {optimal_topics} (coherence: {optimal_coherence:.4f})')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coherence scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_range, coherence_scores, marker='o', linewidth=2, markersize=8)\n",
    "plt.axvline(x=optimal_topics, color='red', linestyle='--', label=f'Optimal: {optimal_topics} topics')\n",
    "plt.xlabel('Number of Topics', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Coherence Score (C_v)', fontsize=12, fontweight='bold')\n",
    "plt.title('Topic Model Coherence Optimization', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/lda_coherence_optimization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Coherence plot saved: figures/lda_coherence_optimization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Final LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final LDA model with optimal number of topics\n",
    "print(f'üîÑ Training final LDA model with {optimal_topics} topics...\\n')\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=optimal_topics,\n",
    "    random_state=42,\n",
    "    passes=15,  # More passes for final model\n",
    "    iterations=400,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "print('‚úÖ LDA model training complete!')\n",
    "\n",
    "# Save model\n",
    "lda_model.save('../../models/lda_aviation_narratives.model')\n",
    "dictionary.save('../../models/lda_dictionary.dict')\n",
    "with open('../../models/lda_corpus.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus, f)\n",
    "\n",
    "print('‚úÖ Model saved to: models/lda_aviation_narratives.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract and Display Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all topics with top 20 words\n",
    "print('='*80)\n",
    "print(f'LDA TOPICS ({optimal_topics} topics, top 20 words per topic)')\n",
    "print('='*80)\n",
    "\n",
    "topic_words = {}\n",
    "\n",
    "for topic_id in range(optimal_topics):\n",
    "    topic_terms = lda_model.show_topic(topic_id, topn=20)\n",
    "    topic_words[topic_id] = topic_terms\n",
    "    \n",
    "    print(f'\\nTopic {topic_id}:')\n",
    "    for word, prob in topic_terms:\n",
    "        print(f'  {word:20s} {prob:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Assign Dominant Topics to Narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dominant topic for each document\n",
    "def get_dominant_topic(doc_topics):\n",
    "    \"\"\"Extract dominant topic from LDA output.\"\"\"\n",
    "    if not doc_topics:\n",
    "        return -1, 0.0\n",
    "    sorted_topics = sorted(doc_topics, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_topics[0]\n",
    "\n",
    "dominant_topics = []\n",
    "dominant_probs = []\n",
    "\n",
    "for doc in corpus:\n",
    "    doc_topics = lda_model.get_document_topics(doc)\n",
    "    topic_id, prob = get_dominant_topic(doc_topics)\n",
    "    dominant_topics.append(topic_id)\n",
    "    dominant_probs.append(prob)\n",
    "\n",
    "df['dominant_topic'] = dominant_topics\n",
    "df['topic_probability'] = dominant_probs\n",
    "\n",
    "print('‚úÖ Dominant topics assigned to all narratives')\n",
    "print(f'\\nTopic distribution:')\n",
    "print(df['dominant_topic'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Topic Distribution Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic distribution\n",
    "topic_counts = df['dominant_topic'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(topic_counts.index, topic_counts.values, color='steelblue', edgecolor='black')\n",
    "plt.xlabel('Topic ID', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Narratives', fontsize=12, fontweight='bold')\n",
    "plt.title(f'Topic Distribution Across {len(df):,} Aviation Accident Narratives', \n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(topic_counts.index)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/lda_topic_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Topic distribution chart saved: figures/lda_topic_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Topic Prevalence Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic prevalence by decade\n",
    "decade_topic = df.groupby(['decade', 'dominant_topic']).size().unstack(fill_value=0)\n",
    "\n",
    "# Normalize by decade (percentage)\n",
    "decade_topic_pct = decade_topic.div(decade_topic.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(\n",
    "    decade_topic_pct.T,\n",
    "    cmap='YlGnBu',\n",
    "    cbar_kws={'label': 'Percentage of Narratives (%)'},\n",
    "    linewidths=0.5,\n",
    "    linecolor='gray',\n",
    "    fmt='.1f',\n",
    "    annot=True\n",
    ")\n",
    "plt.xlabel('Decade', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Topic ID', fontsize=12, fontweight='bold')\n",
    "plt.title('Topic Prevalence Across Decades', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/lda_topic_prevalence_decades.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Topic prevalence heatmap saved: figures/lda_topic_prevalence_decades.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Topic Correlation with Fatal Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fatal rate by topic\n",
    "topic_fatal_rate = df.groupby('dominant_topic')['fatal_outcome'].agg(['sum', 'count', 'mean'])\n",
    "topic_fatal_rate['fatal_rate_pct'] = topic_fatal_rate['mean'] * 100\n",
    "topic_fatal_rate = topic_fatal_rate.sort_values('fatal_rate_pct', ascending=False)\n",
    "\n",
    "print('Fatal Rate by Topic:\\n')\n",
    "print(topic_fatal_rate[['sum', 'count', 'fatal_rate_pct']].to_string())\n",
    "\n",
    "# Plot fatal rates\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#e74c3c' if rate > df['fatal_outcome'].mean() * 100 else '#3498db' \n",
    "          for rate in topic_fatal_rate['fatal_rate_pct']]\n",
    "\n",
    "plt.bar(topic_fatal_rate.index, topic_fatal_rate['fatal_rate_pct'], color=colors, edgecolor='black')\n",
    "plt.axhline(y=df['fatal_outcome'].mean() * 100, color='orange', linestyle='--', \n",
    "            linewidth=2, label=f'Overall Fatal Rate: {df[\"fatal_outcome\"].mean()*100:.1f}%')\n",
    "plt.xlabel('Topic ID', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Fatal Accident Rate (%)', fontsize=12, fontweight='bold')\n",
    "plt.title('Fatal Accident Rate by Topic', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xticks(topic_fatal_rate.index)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/lda_topic_fatal_rates.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Topic fatal rates chart saved: figures/lda_topic_fatal_rates.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Topic Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create word clouds for top 6 topics by size\n",
    "top_topics = topic_counts.nlargest(6).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, topic_id in enumerate(top_topics):\n",
    "    # Get topic words and probabilities\n",
    "    topic_terms = dict(lda_model.show_topic(topic_id, topn=50))\n",
    "    \n",
    "    # Create word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=600,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='viridis',\n",
    "        relative_scaling=0.5\n",
    "    ).generate_from_frequencies(topic_terms)\n",
    "    \n",
    "    axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Topic {topic_id} (n={topic_counts[topic_id]:,})', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.suptitle('Word Clouds for Top 6 Topics', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/lda_topic_wordclouds.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Topic word clouds saved: figures/lda_topic_wordclouds.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('LDA TOPIC MODELING SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nüìä Model Configuration:')\n",
    "print(f'   Number of topics: {optimal_topics}')\n",
    "print(f'   Coherence score (C_v): {optimal_coherence:.4f}')\n",
    "print(f'   Dictionary size: {len(dictionary):,} unique tokens')\n",
    "print(f'   Corpus size: {len(corpus):,} documents')\n",
    "\n",
    "print(f'\\nüìà Topic Statistics:')\n",
    "print(f'   Most prevalent topic: Topic {topic_counts.idxmax()} ({topic_counts.max():,} narratives)')\n",
    "print(f'   Least prevalent topic: Topic {topic_counts.idxmin()} ({topic_counts.min():,} narratives)')\n",
    "print(f'   Average narratives per topic: {topic_counts.mean():.0f}')\n",
    "print(f'   Average topic probability: {df[\"topic_probability\"].mean():.3f}')\n",
    "\n",
    "print(f'\\n‚ö†Ô∏è Fatal Outcome Analysis:')\n",
    "print(f'   Overall fatal rate: {df[\"fatal_outcome\"].mean()*100:.1f}%')\n",
    "print(f'   Highest fatal rate: Topic {topic_fatal_rate.index[0]} ({topic_fatal_rate[\"fatal_rate_pct\"].iloc[0]:.1f}%)')\n",
    "print(f'   Lowest fatal rate: Topic {topic_fatal_rate.index[-1]} ({topic_fatal_rate[\"fatal_rate_pct\"].iloc[-1]:.1f}%)')\n",
    "\n",
    "print(f'\\nüíæ Artifacts Created:')\n",
    "print(f'   Model: models/lda_aviation_narratives.model')\n",
    "print(f'   Dictionary: models/lda_dictionary.dict')\n",
    "print(f'   Corpus: models/lda_corpus.pkl')\n",
    "\n",
    "print(f'\\nüìä Visualizations Created:')\n",
    "print(f'   1. Coherence optimization plot')\n",
    "print(f'   2. Topic distribution bar chart')\n",
    "print(f'   3. Topic prevalence heatmap (decades)')\n",
    "print(f'   4. Topic fatal rates comparison')\n",
    "print(f'   5. Topic word clouds (top 6 topics)')\n",
    "\n",
    "print('\\n‚úÖ LDA Topic Modeling Complete!')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export topic assignments\n",
    "topic_assignments = df[['ev_id', 'ev_year', 'decade', 'dominant_topic', 'topic_probability', 'fatal_outcome']]\n",
    "topic_assignments.to_csv('../../data/lda_topic_assignments.csv', index=False)\n",
    "print('‚úÖ Exported topic assignments to: data/lda_topic_assignments.csv')\n",
    "\n",
    "# Export topic words\n",
    "topic_words_export = []\n",
    "for topic_id in range(optimal_topics):\n",
    "    for word, prob in topic_words[topic_id]:\n",
    "        topic_words_export.append({\n",
    "            'topic_id': topic_id,\n",
    "            'word': word,\n",
    "            'probability': prob\n",
    "        })\n",
    "\n",
    "topic_words_df = pd.DataFrame(topic_words_export)\n",
    "topic_words_df.to_csv('../../data/lda_topic_words.csv', index=False)\n",
    "print('‚úÖ Exported topic words to: data/lda_topic_words.csv')\n",
    "\n",
    "# Export topic statistics\n",
    "topic_stats = pd.DataFrame({\n",
    "    'topic_id': topic_counts.index,\n",
    "    'narrative_count': topic_counts.values,\n",
    "    'fatal_count': topic_fatal_rate.loc[topic_counts.index, 'sum'].values,\n",
    "    'fatal_rate_pct': topic_fatal_rate.loc[topic_counts.index, 'fatal_rate_pct'].values\n",
    "})\n",
    "topic_stats.to_csv('../../data/lda_topic_statistics.csv', index=False)\n",
    "print('‚úÖ Exported topic statistics to: data/lda_topic_statistics.csv')\n",
    "\n",
    "print('\\nüéâ All LDA analysis results saved successfully!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}