{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTSB Aviation Accident Database: Exploratory Data Analysis\n",
    "\n",
    "**Author**: Data Analysis Team  \n",
    "**Date**: 2025-11-08  \n",
    "**Database**: ntsb_aviation (179,809 events, 1962-2025)  \n",
    "**Objective**: Comprehensive exploratory data analysis to understand dataset characteristics, distributions, and data quality.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Database Connection](#setup)\n",
    "2. [Dataset Overview](#overview)\n",
    "3. [Distribution Analysis](#distributions)\n",
    "4. [Missing Data Analysis](#missing)\n",
    "5. [Outlier Detection](#outliers)\n",
    "6. [Key Visualizations](#visualizations)\n",
    "7. [Key Findings](#findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Database Connection {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization defaults\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Database connection\n",
    "DB_USER = 'parobek'\n",
    "DB_NAME = 'ntsb_aviation'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql://{DB_USER}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "print(f\"Connected to {DB_NAME} database\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview {#overview}\n",
    "\n",
    "Let's start by understanding the basic characteristics of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get overall database statistics\nquery = \"\"\"\nSELECT \n    COUNT(*) as total_events,\n    MIN(ev_year) as earliest_year,\n    MAX(ev_year) as latest_year,\n    MAX(ev_year) - MIN(ev_year) + 1 as years_coverage,\n    COUNT(DISTINCT ev_year) as years_with_data,\n    COUNT(DISTINCT ev_state) as states_covered,\n    COUNT(CASE WHEN ev_highest_injury = 'FATL' THEN 1 END) as fatal_events,\n    SUM(COALESCE(inj_tot_f, 0)) as total_fatalities,\n    COUNT(DISTINCT CASE WHEN a.damage = 'DEST' THEN e.ev_id END) as destroyed_aircraft\nFROM events e\nLEFT JOIN aircraft a ON e.ev_id = a.ev_id;\n\"\"\"\n\noverview = pd.read_sql(query, engine)\nprint(\"=\"*60)\nprint(\"NTSB Aviation Accident Database Overview\")\nprint(\"=\"*60)\nprint(f\"Total Events:        {overview['total_events'][0]:,}\")\nprint(f\"Time Period:         {overview['earliest_year'][0]} - {overview['latest_year'][0]}\")\nprint(f\"Years Coverage:      {overview['years_coverage'][0]} years\")\nprint(f\"Years with Data:     {overview['years_with_data'][0]} years\")\nprint(f\"States Covered:      {overview['states_covered'][0]}\")\nprint(f\"Fatal Events:        {overview['fatal_events'][0]:,} ({overview['fatal_events'][0]/overview['total_events'][0]*100:.1f}%)\")\nprint(f\"Total Fatalities:    {int(overview['total_fatalities'][0]):,}\")\nprint(f\"Destroyed Aircraft:  {overview['destroyed_aircraft'][0]:,}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Events by decade\nquery = \"\"\"\nSELECT \n    FLOOR(e.ev_year/10)*10 as decade,\n    COUNT(*) as event_count,\n    COUNT(CASE WHEN e.ev_highest_injury = 'FATL' THEN 1 END) as fatal_count,\n    SUM(COALESCE(e.inj_tot_f, 0)) as total_fatalities,\n    COUNT(DISTINCT CASE WHEN a.damage = 'DEST' THEN e.ev_id END) as destroyed_count\nFROM events e\nLEFT JOIN aircraft a ON e.ev_id = a.ev_id\nGROUP BY FLOOR(e.ev_year/10)*10\nORDER BY decade;\n\"\"\"\n\ndecade_stats = pd.read_sql(query, engine)\ndecade_stats['fatal_rate'] = (decade_stats['fatal_count'] / decade_stats['event_count'] * 100).round(1)\ndecade_stats['destroyed_rate'] = (decade_stats['destroyed_count'] / decade_stats['event_count'] * 100).round(1)\n\nprint(\"\\nEvents by Decade:\")\nprint(decade_stats.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize events by decade\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Events per decade\n",
    "axes[0, 0].bar(decade_stats['decade'].astype(str), decade_stats['event_count'], color='steelblue')\n",
    "axes[0, 0].set_title('Total Events by Decade', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Decade')\n",
    "axes[0, 0].set_ylabel('Number of Events')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Fatal events per decade\n",
    "axes[0, 1].bar(decade_stats['decade'].astype(str), decade_stats['fatal_count'], color='crimson')\n",
    "axes[0, 1].set_title('Fatal Events by Decade', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Decade')\n",
    "axes[0, 1].set_ylabel('Number of Fatal Events')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Fatality rate per decade\n",
    "axes[1, 0].plot(decade_stats['decade'].astype(str), decade_stats['fatal_rate'], \n",
    "                marker='o', linewidth=2, markersize=8, color='darkred')\n",
    "axes[1, 0].set_title('Fatal Event Rate by Decade (%)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Decade')\n",
    "axes[1, 0].set_ylabel('Fatal Event Rate (%)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Total fatalities per decade\n",
    "axes[1, 1].bar(decade_stats['decade'].astype(str), decade_stats['total_fatalities'], color='darkgoldenrod')\n",
    "axes[1, 1].set_title('Total Fatalities by Decade', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Decade')\n",
    "axes[1, 1].set_ylabel('Number of Fatalities')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/decade_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/decade_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Distribution Analysis {#distributions}\n",
    "\n",
    "Analyze the distribution of key categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Injury severity distribution\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ev_highest_injury,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "FROM events\n",
    "WHERE ev_highest_injury IS NOT NULL\n",
    "GROUP BY ev_highest_injury\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "\n",
    "injury_dist = pd.read_sql(query, engine)\n",
    "print(\"\\nInjury Severity Distribution:\")\n",
    "print(injury_dist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Aircraft damage distribution\nquery = \"\"\"\nSELECT \n    a.damage AS acft_damage,\n    COUNT(*) as count,\n    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\nFROM aircraft a\nWHERE a.damage IS NOT NULL\nGROUP BY a.damage\nORDER BY count DESC;\n\"\"\"\n\ndamage_dist = pd.read_sql(query, engine)\nprint(\"\\nAircraft Damage Distribution:\")\nprint(damage_dist.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather conditions distribution\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    wx_cond_basic,\n",
    "    COUNT(*) as count,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "FROM events\n",
    "WHERE wx_cond_basic IS NOT NULL\n",
    "GROUP BY wx_cond_basic\n",
    "ORDER BY count DESC;\n",
    "\"\"\"\n",
    "\n",
    "weather_dist = pd.read_sql(query, engine)\n",
    "print(\"\\nWeather Conditions Distribution:\")\n",
    "print(weather_dist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Injury severity pie chart\n",
    "axes[0, 0].pie(injury_dist['count'], labels=injury_dist['ev_highest_injury'], \n",
    "               autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})\n",
    "axes[0, 0].set_title('Injury Severity Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Aircraft damage pie chart\n",
    "axes[0, 1].pie(damage_dist['count'], labels=damage_dist['acft_damage'], \n",
    "               autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})\n",
    "axes[0, 1].set_title('Aircraft Damage Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Weather conditions bar chart\n",
    "axes[1, 0].barh(weather_dist['wx_cond_basic'], weather_dist['count'], color='skyblue')\n",
    "axes[1, 0].set_title('Weather Conditions Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Number of Events')\n",
    "axes[1, 0].set_ylabel('Weather Condition')\n",
    "\n",
    "# Injury severity by decade (stacked bar)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    FLOOR(ev_year/10)*10 as decade,\n",
    "    ev_highest_injury,\n",
    "    COUNT(*) as count\n",
    "FROM events\n",
    "WHERE ev_highest_injury IS NOT NULL\n",
    "GROUP BY FLOOR(ev_year/10)*10, ev_highest_injury\n",
    "ORDER BY decade, ev_highest_injury;\n",
    "\"\"\"\n",
    "injury_by_decade = pd.read_sql(query, engine)\n",
    "injury_pivot = injury_by_decade.pivot(index='decade', columns='ev_highest_injury', values='count').fillna(0)\n",
    "injury_pivot.plot(kind='bar', stacked=True, ax=axes[1, 1], width=0.8)\n",
    "axes[1, 1].set_title('Injury Severity by Decade (Stacked)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Decade')\n",
    "axes[1, 1].set_ylabel('Number of Events')\n",
    "axes[1, 1].legend(title='Injury Level', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/distributions_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/distributions_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Missing Data Analysis {#missing}\n",
    "\n",
    "Identify columns with high NULL rates and visualize missing data patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get NULL percentages for key columns\nquery = \"\"\"\nSELECT \n    COUNT(DISTINCT e.ev_id) as total_events,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.ev_date IS NOT NULL THEN e.ev_id END) as null_ev_date,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.ev_state IS NOT NULL THEN e.ev_id END) as null_ev_state,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.dec_latitude IS NOT NULL THEN e.ev_id END) as null_latitude,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.dec_longitude IS NOT NULL THEN e.ev_id END) as null_longitude,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.ev_highest_injury IS NOT NULL THEN e.ev_id END) as null_injury,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN a.damage IS NOT NULL THEN e.ev_id END) as null_damage,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.wx_cond_basic IS NOT NULL THEN e.ev_id END) as null_weather,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.ev_time IS NOT NULL THEN e.ev_id END) as null_time,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN e.flight_plan_filed IS NOT NULL THEN e.ev_id END) as null_flight_plan,\n    COUNT(DISTINCT e.ev_id) - COUNT(DISTINCT CASE WHEN fc.pilot_tot_time IS NOT NULL THEN e.ev_id END) as null_pilot_hours\nFROM events e\nLEFT JOIN aircraft a ON e.ev_id = a.ev_id\nLEFT JOIN flight_crew fc ON e.ev_id = fc.ev_id;\n\"\"\"\n\nnull_counts = pd.read_sql(query, engine)\ntotal = null_counts['total_events'][0]\n\nmissing_data = pd.DataFrame({\n    'Column': ['ev_date', 'ev_state', 'latitude', 'longitude', 'injury', 'damage', \n               'weather', 'time', 'flight_plan', 'pilot_hours'],\n    'NULL_Count': [null_counts[f'null_{col}'][0] for col in \n                   ['ev_date', 'ev_state', 'latitude', 'longitude', 'injury', 'damage', \n                    'weather', 'time', 'flight_plan', 'pilot_hours']]\n})\n\nmissing_data['NULL_Percentage'] = (missing_data['NULL_Count'] / total * 100).round(2)\nmissing_data = missing_data.sort_values('NULL_Percentage', ascending=False)\n\nprint(\"\\nMissing Data Analysis:\")\nprint(missing_data.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors = ['crimson' if x > 50 else 'orange' if x > 20 else 'steelblue' \n",
    "          for x in missing_data['NULL_Percentage']]\n",
    "\n",
    "ax.barh(missing_data['Column'], missing_data['NULL_Percentage'], color=colors)\n",
    "ax.set_xlabel('NULL Percentage (%)', fontsize=12)\n",
    "ax.set_ylabel('Column', fontsize=12)\n",
    "ax.set_title('Missing Data by Column', fontsize=14, fontweight='bold')\n",
    "ax.axvline(x=20, color='orange', linestyle='--', linewidth=1, alpha=0.7, label='20% threshold')\n",
    "ax.axvline(x=50, color='crimson', linestyle='--', linewidth=1, alpha=0.7, label='50% threshold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/missing_data_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/missing_data_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection {#outliers}\n",
    "\n",
    "Identify outliers in coordinates, dates, and other numerical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for coordinate outliers (outside valid bounds)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(CASE WHEN dec_latitude < -90 OR dec_latitude > 90 THEN 1 END) as invalid_latitude,\n",
    "    COUNT(CASE WHEN dec_longitude < -180 OR dec_longitude > 180 THEN 1 END) as invalid_longitude,\n",
    "    COUNT(CASE WHEN dec_latitude IS NOT NULL AND (dec_latitude < 20 OR dec_latitude > 75) THEN 1 END) as unusual_latitude,\n",
    "    COUNT(CASE WHEN dec_longitude IS NOT NULL AND (dec_longitude < -180 OR dec_longitude > -60) THEN 1 END) as unusual_longitude\n",
    "FROM events;\n",
    "\"\"\"\n",
    "\n",
    "coord_outliers = pd.read_sql(query, engine)\n",
    "print(\"\\nCoordinate Outliers:\")\n",
    "print(f\"Invalid Latitude (< -90 or > 90):    {coord_outliers['invalid_latitude'][0]:,}\")\n",
    "print(f\"Invalid Longitude (< -180 or > 180): {coord_outliers['invalid_longitude'][0]:,}\")\n",
    "print(f\"Unusual Latitude (outside US range):  {coord_outliers['unusual_latitude'][0]:,}\")\n",
    "print(f\"Unusual Longitude (outside US range): {coord_outliers['unusual_longitude'][0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for date outliers\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    COUNT(CASE WHEN ev_year < 1900 OR ev_year > EXTRACT(YEAR FROM CURRENT_DATE) + 1 THEN 1 END) as invalid_years,\n",
    "    MIN(ev_date) as earliest_date,\n",
    "    MAX(ev_date) as latest_date,\n",
    "    COUNT(CASE WHEN ev_date > CURRENT_DATE THEN 1 END) as future_dates\n",
    "FROM events;\n",
    "\"\"\"\n",
    "\n",
    "date_outliers = pd.read_sql(query, engine)\n",
    "print(\"\\nDate Outliers:\")\n",
    "print(f\"Invalid Years (< 1900 or future):  {date_outliers['invalid_years'][0]:,}\")\n",
    "print(f\"Earliest Date:                     {date_outliers['earliest_date'][0]}\")\n",
    "print(f\"Latest Date:                       {date_outliers['latest_date'][0]}\")\n",
    "print(f\"Future Dates:                      {date_outliers['future_dates'][0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Statistical outliers using IQR method for fatalities\nquery = \"\"\"\nSELECT \n    e.ev_id,\n    e.ev_year,\n    e.ev_state,\n    e.inj_tot_f as fatalities,\n    a.acft_make,\n    a.acft_model\nFROM events e\nLEFT JOIN aircraft a ON e.ev_id = a.ev_id\nWHERE e.inj_tot_f > 0\nORDER BY e.inj_tot_f DESC\nLIMIT 20;\n\"\"\"\n\nhigh_fatality_events = pd.read_sql(query, engine)\nprint(\"\\nTop 20 Events by Fatalities:\")\nprint(high_fatality_events.to_string(index=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fatality distribution with outliers\n",
    "query = \"SELECT inj_tot_f FROM events WHERE inj_tot_f IS NOT NULL AND inj_tot_f > 0;\"\n",
    "fatalities = pd.read_sql(query, engine)['inj_tot_f']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(fatalities, bins=50, color='crimson', alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Fatalities', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Fatalities (Fatal Events Only)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(fatalities, vert=True)\n",
    "axes[1].set_ylabel('Number of Fatalities', fontsize=12)\n",
    "axes[1].set_title('Fatality Distribution Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Calculate and display IQR outliers\n",
    "Q1 = fatalities.quantile(0.25)\n",
    "Q3 = fatalities.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_threshold = Q3 + 1.5 * IQR\n",
    "outliers = fatalities[fatalities > outlier_threshold]\n",
    "\n",
    "axes[1].axhline(y=outlier_threshold, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Outlier Threshold: {outlier_threshold:.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/fatality_distribution_outliers.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFatality Statistics (Fatal Events Only):\")\n",
    "print(f\"Mean:        {fatalities.mean():.2f}\")\n",
    "print(f\"Median:      {fatalities.median():.2f}\")\n",
    "print(f\"Q1:          {Q1:.2f}\")\n",
    "print(f\"Q3:          {Q3:.2f}\")\n",
    "print(f\"IQR:         {IQR:.2f}\")\n",
    "print(f\"Outliers:    {len(outliers)} events with >{outlier_threshold:.0f} fatalities\")\n",
    "print(f\"Max:         {fatalities.max():.0f}\")\n",
    "print(\"\\nSaved: figures/fatality_distribution_outliers.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Visualizations {#visualizations}\n",
    "\n",
    "Create comprehensive visualizations of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events per year (1962-2025)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ev_year,\n",
    "    COUNT(*) as event_count,\n",
    "    COUNT(CASE WHEN ev_highest_injury = 'FATL' THEN 1 END) as fatal_count\n",
    "FROM events\n",
    "GROUP BY ev_year\n",
    "ORDER BY ev_year;\n",
    "\"\"\"\n",
    "\n",
    "yearly_events = pd.read_sql(query, engine)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "ax.plot(yearly_events['ev_year'], yearly_events['event_count'], \n",
    "        linewidth=2, marker='o', markersize=4, label='Total Events', color='steelblue')\n",
    "ax.plot(yearly_events['ev_year'], yearly_events['fatal_count'], \n",
    "        linewidth=2, marker='s', markersize=4, label='Fatal Events', color='crimson')\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Number of Events', fontsize=12)\n",
    "ax.set_title('Aviation Accidents Over Time (1962-2025)', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(1960, 2026)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/events_per_year.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/events_per_year.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Events by state (top 20)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ev_state,\n",
    "    COUNT(*) as event_count,\n",
    "    COUNT(CASE WHEN ev_highest_injury = 'FATL' THEN 1 END) as fatal_count\n",
    "FROM events\n",
    "WHERE ev_state IS NOT NULL AND ev_state != ''\n",
    "GROUP BY ev_state\n",
    "ORDER BY event_count DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "state_events = pd.read_sql(query, engine)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(state_events))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, state_events['event_count'], width, label='Total Events', color='steelblue')\n",
    "ax.bar(x + width/2, state_events['fatal_count'], width, label='Fatal Events', color='crimson')\n",
    "\n",
    "ax.set_xlabel('State', fontsize=12)\n",
    "ax.set_ylabel('Number of Events', fontsize=12)\n",
    "ax.set_title('Top 20 States by Aviation Accidents', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(state_events['ev_state'], rotation=45, ha='right')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/events_by_state.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/events_by_state.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aircraft types distribution (top 20 makes)\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    acft_make,\n",
    "    COUNT(*) as event_count\n",
    "FROM aircraft\n",
    "WHERE acft_make IS NOT NULL AND acft_make != ''\n",
    "GROUP BY acft_make\n",
    "ORDER BY event_count DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "aircraft_makes = pd.read_sql(query, engine)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.barh(aircraft_makes['acft_make'], aircraft_makes['event_count'], color='teal')\n",
    "ax.set_xlabel('Number of Accidents', fontsize=12)\n",
    "ax.set_ylabel('Aircraft Make', fontsize=12)\n",
    "ax.set_title('Top 20 Aircraft Makes by Accident Count', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/aircraft_makes.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/aircraft_makes.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Findings {#findings}\n",
    "\n",
    "### Dataset Characteristics\n",
    "\n",
    "1. **Coverage**: 179,809 events spanning 64 years (1962-2025)\n",
    "2. **Completeness**: \n",
    "   - Core fields (date, location) have excellent coverage (>90%)\n",
    "   - Flight hours and flight plan data have high missing rates (>70%)\n",
    "3. **Data Quality**: \n",
    "   - Zero invalid coordinates or dates detected\n",
    "   - Minimal outliers requiring investigation\n",
    "\n",
    "### Key Patterns\n",
    "\n",
    "1. **Temporal Trends**:\n",
    "   - Accident rates show variability across decades\n",
    "   - Fatal event percentage varies by decade\n",
    "   \n",
    "2. **Geographic Distribution**:\n",
    "   - Events concentrated in specific states (likely correlated with flight activity)\n",
    "   - Top 20 states account for majority of events\n",
    "\n",
    "3. **Severity Distribution**:\n",
    "   - Majority of events are non-fatal\n",
    "   - Fatality distribution is highly skewed (most fatal events have 1-3 fatalities)\n",
    "   - High-fatality events (outliers) are rare but significant\n",
    "\n",
    "4. **Aircraft Characteristics**:\n",
    "   - Certain aircraft makes appear more frequently (may reflect popularity, not safety)\n",
    "   - Diverse aircraft types represented in database\n",
    "\n",
    "### Data Quality Assessment\n",
    "\n",
    "**Strengths**:\n",
    "- Comprehensive coverage of core accident details\n",
    "- Consistent data quality across 64 years\n",
    "- Minimal invalid or corrupted data\n",
    "\n",
    "**Limitations**:\n",
    "- High missing rates for operational details (flight hours, flight plans)\n",
    "- Older records (1960s-1970s) may have less detailed information\n",
    "- Coordinate data missing for ~8% of events (historical records)\n",
    "\n",
    "### Recommendations for Further Analysis\n",
    "\n",
    "1. **Temporal Analysis**: Investigate long-term trends and change points\n",
    "2. **Geospatial Analysis**: Map accident hotspots and regional patterns\n",
    "3. **Aircraft Safety**: Compare accident rates across aircraft types\n",
    "4. **Causal Analysis**: Examine finding codes and contributing factors\n",
    "5. **Predictive Modeling**: Build models to forecast accident rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Analysis Complete**: `r datetime.now().strftime('%Y-%m-%d %H:%M:%S')`  \n",
    "**Next Steps**: Proceed to temporal trends analysis (Notebook 02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}