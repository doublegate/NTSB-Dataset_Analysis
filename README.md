# NTSB Aviation Accident Database Analysis

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Database Size](https://img.shields.io/badge/Database%20Size-801%20MB-blue.svg)](https://github.com/doublegate/NTSB-Dataset_Analysis)
[![Events](https://img.shields.io/badge/Events-179%2C809-green.svg)](https://github.com/doublegate/NTSB-Dataset_Analysis)
[![Coverage](https://img.shields.io/badge/Coverage-1962--2025%20(64%20years)-brightgreen.svg)](https://github.com/doublegate/NTSB-Dataset_Analysis)
[![Last Commit](https://img.shields.io/github/last-commit/doublegate/NTSB-Dataset_Analysis?label=Last%20Commit)](https://github.com/doublegate/NTSB-Dataset_Analysis/commits/main)
[![Data Source: NTSB](https://img.shields.io/badge/Data-NTSB-blue.svg)](https://www.ntsb.gov/Pages/AviationQueryV2.aspx)
[![Fish Shell](https://img.shields.io/badge/Shell-Fish-green.svg)](https://fishshell.com/)
[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)

## Overview

### Introduction

Aviation safety has transformed dramatically over the past six decades, yet comprehensive analysis of historical accident data remains fragmented across disparate systems and formats. The **NTSB Aviation Accident Database** project addresses this challenge by providing a production-ready analytics platform that integrates 64 years of National Transportation Safety Board investigation records into a unified, queryable system.

This platform serves **data scientists** seeking statistical rigor, **aviation researchers** analyzing safety trends, **software developers** building safety applications, **regulatory analysts** informing policy decisions, and **students and educators** exploring aviation safety through data. By consolidating three historical NTSB databases (1962-1981, 1982-2007, 2008-present) into a single PostgreSQL database with comprehensive ETL automation, we eliminate the technical barriers that have historically limited aviation safety research.

**What makes this unique**: Complete historical coverage with zero date gaps, production-grade data quality (98/100 health score), automated monthly updates via Apache Airflow, and a comprehensive suite of analysis tools spanning exploratory data analysis to machine learning preparation. The project delivers not just data access, but actionable insights‚Äîstatistical evidence of declining accident rates, identification of critical risk factors, and evidence-based recommendations for pilots, regulators, and manufacturers.

**Current Status**: Phase 1 COMPLETE (infrastructure), Phase 2 COMPLETE (analytics). Production-ready for December 1st, 2025 first automated monthly sync.

### Technical Summary

**Database Infrastructure**:
- **PostgreSQL 18.0** with PostGIS extension for geospatial analysis
- **179,809 aviation accident events** from 1962-2025 (64 years, complete coverage)
- **801 MB optimized database** with ~1.3M rows across 13 tables
- **Query Performance**: p50 2ms, p95 13ms, p99 47ms (all targets met)
- **Cache Efficiency**: 96.48% buffer cache hit ratio, 99.98% index usage on primary tables
- **Data Quality**: 100% (zero duplicates, zero orphans, 100% foreign key integrity)

**ETL Automation**:
- **Apache Airflow** orchestration with 8-task production DAG
- **Monthly automated sync** (scheduled 1st of month, 2 AM)
- **Smart duplicate detection** via staging table pattern
- **Load tracking system** prevents accidental re-loads of historical data
- **Monitoring infrastructure** with Slack/Email alerts and 5 automated quality checks

**Code Quality & Performance**:
- **Python**: ruff-formatted, PEP 8 compliant, comprehensive type hints
- **SQL**: Optimized with 6 materialized views (30-114x speedup), 59 indexes
- **Database Maintenance**: Automated 10-phase grooming (~8 seconds execution)
- **Technologies**: PostgreSQL, PostGIS, Python 3.11+, Apache Airflow, Docker, pandas, scikit-learn, matplotlib

**Architecture**:
- **11 core tables** with relational integrity (events, aircraft, findings, narratives, etc.)
- **5 code mapping tables** decoding 945+ legacy NTSB codes
- **6 materialized views** for analytical queries (yearly stats, state stats, aircraft stats, etc.)
- **4 monitoring views** for real-time health checks (database metrics, data quality, monthly trends, system health)

### Features

#### Data Infrastructure
- **Complete NTSB Database Integration**: Three source databases unified (avall.mdb, Pre2008.mdb, PRE1982.MDB)
- **64-Year Historical Coverage**: 1962-2025 with zero date gaps (179,809 events)
- **Optimized Schema**: 13 tables, 59 indexes, 6 materialized views, PostGIS geospatial support
- **Code Mapping System**: 945+ legacy codes decoded across 5 lookup tables
- **Data Quality**: 98/100 health score (zero duplicates, 100% FK integrity, validated coordinates)

#### ETL & Automation
- **Apache Airflow Pipeline**: Production DAG with 8 tasks (check, download, extract, backup, load, validate, refresh, notify)
- **Monthly Automated Sync**: Scheduled updates from NTSB with smart skip logic
- **Staging Infrastructure**: Safe data loading with duplicate detection and rollback capability
- **Load Tracking**: Prevents accidental reloads, tracks load history and statistics
- **Error Recovery**: Comprehensive error handling with graceful degradation

#### Data Analysis
- **15 Jupyter Notebooks** (5,335+ lines): Exploratory, modeling, geospatial, NLP & text mining
- **Statistical Models**: Chi-square tests, Mann-Whitney U, linear regression, ARIMA forecasting, logistic regression, random forest
- **Geospatial Methods**: DBSCAN clustering, KDE heatmaps, Getis-Ord Gi* hotspot analysis, Moran's I spatial autocorrelation
- **NLP Methods**: TF-IDF vectorization, LDA topic modeling, Word2Vec embeddings, NER, sentiment analysis
- **40+ Visualizations**: Publication-quality figures (PNG, 150 DPI) + interactive Folium maps
- **6 Comprehensive Reports**: Sprint summaries, 64-year analysis, ML modeling, geospatial, NLP & text mining findings
- **Key Findings**: 31% decline in accidents since 2000 (p < 0.001), 64 spatial clusters, 10 latent topics, sentiment correlates with fatal outcomes (p < 0.001)

#### Performance & Reliability
- **Sub-Millisecond Queries**: Materialized views for common analytics (p50 1-2ms)
- **Cache Hit Ratio**: 96.48% (excellent memory utilization)
- **Index Usage**: 99.98% on primary tables (events, aircraft)
- **Database Health**: 98/100 score (excellent), zero bloat, zero dead tuples
- **Automated Maintenance**: 10-phase grooming script (~8 seconds execution)

#### Monitoring & Observability
- **Slack Integration**: Real-time webhook alerts (<30s latency) for DAG failures and successes
- **Email Notifications**: SMTP support (Gmail App Password, SendGrid, AWS SES)
- **5 Automated Quality Checks**: Missing fields, coordinate outliers, statistical anomalies, referential integrity, duplicates
- **4 Monitoring Views**: Database metrics, data quality, monthly trends, system health (all <50ms query time)
- **Anomaly Detection**: CLI tool with JSON output, exit codes for integration

#### Documentation & Support
- **20+ Markdown Guides**: Setup, troubleshooting, monitoring, performance, ETL, schema reference
- **API Documentation**: Complete script and notebook documentation with examples
- **Sprint Completion Reports**: Detailed deliverables, metrics, and lessons learned for all 4 sprints
- **Comprehensive README**: Quick start, installation, example queries, recommended tools
- **CHANGELOG**: Complete version history with migration paths

## Table of Contents

- [Features](#features)
- [Datasets](#datasets)
- [Database Structure](#database-structure)
- [NTSB Coding System](#ntsb-coding-system)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Documentation](#documentation)
- [üìö Comprehensive Documentation](#-comprehensive-documentation)
  - [Core Documentation (docs/)](#core-documentation-docs)
  - [Supporting Documentation (docs/supporting/)](#supporting-documentation-docssupporting)
  - [Project Roadmap (to-dos/)](#project-roadmap-to-dos)
  - [Key Highlights](#key-highlights)
- [Example Queries](#example-queries)
- [Recommended Tools](#recommended-tools)
- [Use Cases](#use-cases)
- [Data Updates](#data-updates)
- [Recent Improvements](#recent-improvements)
- [Testing Results](#testing-results)
- [Project Status](#project-status)
- [Next Steps (Phase 2)](#next-steps-phase-2)
- [Contributing](#contributing)
- [License](#license)
- [Resources](#resources)

## Features

- **Three comprehensive databases** spanning 1962-present with 60+ years of accident data
- **PostgreSQL database** with optimized schema, materialized views, and 59 indexes
- **Automated database setup** (`setup_database.sh`) for one-command initialization
- **Production-grade ETL pipelines** with staging tables and duplicate detection
- **Automated extraction scripts** for converting MDB databases to CSV/SQLite/PostgreSQL formats
- **Fast SQL query tools** using DuckDB and PostgreSQL for rapid data analytics
- **Query optimization** with 6 materialized views for common analytical queries
- **Data validation framework** with comprehensive quality checks
- **Python analysis examples** with pandas, polars, and visualization libraries
- **Geospatial analysis** capabilities with PostGIS, mapping and hotspot identification
- **Text mining tools** for analyzing accident narratives and investigation reports
- **Jupyter notebooks** for interactive data exploration
- **Complete documentation** including database schema, coding manual references, and installation guides
- **Fish shell scripts** for streamlined workflow automation
- **Cross-format support** (MDB, CSV, SQLite, PostgreSQL, Parquet) for flexible analysis

## üìä Datasets

This repository contains three comprehensive Microsoft Access databases and an optimized PostgreSQL database:

### Source Databases (MDB Files)

| Database | Time Period | Size | Records | Status |
|----------|-------------|------|---------|--------|
| `datasets/avall.mdb` | 2008 - Present | 537 MB | Updated monthly | ‚úÖ Integrated (Airflow automation) |
| `datasets/Pre2008.mdb` | 1982 - 2007 | 893 MB | Static snapshot | ‚úÖ Integrated (historical) |
| `datasets/PRE1982.MDB` | 1962 - 1981 | 188 MB | 87,038 events | ‚úÖ Integrated (legacy ETL) |

### PostgreSQL Database

| Database | Events | Total Rows | Size | Coverage |
|----------|--------|------------|------|----------|
| `ntsb_aviation` | 179,809 | ~1.3M | 801 MB | 1962-2025 (64 years) |

**Features:**
- Complete 64-year historical coverage (1962-2025, zero gaps)
- Optimized schema with PostGIS for geospatial analysis
- 6 materialized views for fast analytical queries
- 59 indexes for query performance (96.48% buffer cache hit ratio)
- Code mapping system (5 tables, 945+ legacy codes decoded)
- Data quality: 100% (zero duplicates, zero orphans, 100% FK integrity)
- Automated Airflow ETL pipeline with monitoring and notifications
- Anomaly detection with Slack/Email alerts
- Database health score: 98/100 (excellent)

## Database Structure

### Core Tables

The databases follow a relational structure with the following primary tables:

- **events** - Master accident/incident records (keyed by `ev_id`)
- **aircraft** - Aircraft involved in each event
- **Flight_Crew** - Pilot and crew information
- **injury** - Injury details and fatality counts
- **Findings** - Investigation findings and probable causes
- **Occurrences** - Specific events during accidents
- **seq_of_events** - Timeline of events leading to accidents
- **engines** - Engine specifications and failures
- **narratives** - Detailed textual descriptions

### Key Relationships

- `ev_id` - Primary key linking events across most tables
- `Aircraft_Key` - Identifies specific aircraft within events
- Foreign key relationships documented in `ref_docs/eadmspub.pdf`

For complete schema documentation with entity relationship diagrams, see `ref_docs/eadmspub.pdf`.

## NTSB Coding System

NTSB uses a hierarchical coding system to classify accidents (see `ref_docs/codman.pdf`):

- **100-430**: Occurrence types (engine failure, midair collision, fuel exhaustion, etc.)
- **500-610**: Phase of operation (taxi, takeoff, cruise, approach, landing, etc.)
- **10000-21104**: Aircraft/equipment subjects (airframe, systems, powerplant)
- **22000-25000**: Performance, operations, ATC, maintenance
- **30000-84200**: Direct underlying causes
- **90000-93300**: Indirect contributing factors

## Quick Start

Get started analyzing NTSB data in under 5 minutes:

### Option A: PostgreSQL Database (Recommended)

For optimal query performance and advanced analytics:

```bash
# 1. Clone the repository
git clone https://github.com/doublegate/NTSB-Dataset_Analysis.git
cd NTSB-Dataset_Analysis

# 2. Setup PostgreSQL database (automated one-command setup)
./scripts/setup_database.sh

# 3. Load current data (2008-present)
source .venv/bin/activate
python scripts/load_with_staging.py --source datasets/avall.mdb

# 4. Load historical data (1982-2007)
python scripts/load_with_staging.py --source datasets/Pre2008.mdb

# 5. Load legacy data (1962-1981, one-time setup)
python scripts/load_pre1982.py

# 6. Optimize queries (create materialized views + indexes)
psql -d ntsb_aviation -f scripts/optimize_queries.sql

# 7. Run database maintenance (monthly recommended)
./scripts/maintain_database.sh ntsb_aviation

# 8. Run performance benchmarks (optional)
psql -d ntsb_aviation -f scripts/test_performance.sql

# 9. Start querying (sub-millisecond response times)
psql -d ntsb_aviation -c "SELECT * FROM mv_yearly_stats ORDER BY year DESC LIMIT 5;"
```

See [QUICKSTART.md](QUICKSTART.md) for detailed PostgreSQL setup and usage.

### Option B: CSV/DuckDB Analysis

For quick exploration without database setup:

```fish
# 1. Clone the repository
git clone https://github.com/doublegate/NTSB-Dataset_Analysis.git
cd NTSB-Dataset_Analysis

# 2. Automated Setup
./setup.fish  # Install tools: mdbtools, Python, Rust tools
source .venv/bin/activate.fish

# 3. Extract Data from Databases
./scripts/extract_all_tables.fish datasets/avall.mdb

# 4. Start Analyzing
# Quick analysis (100 recent events)
.venv/bin/python examples/quick_analysis.py

# Comprehensive analysis (5 analyses, summary report)
.venv/bin/python examples/advanced_analysis.py

# Interactive maps (requires folium)
.venv/bin/python examples/geospatial_analysis.py

# Or launch Jupyter for interactive work
jupyter lab
# Open examples/starter_notebook.ipynb
```

### Option C: Airflow ETL Pipeline (Automated Monthly Updates)

**Status**: ‚úÖ Sprint 3 Complete - Production-Ready with Monitoring

For automated ETL workflows with scheduling, monitoring, and notifications:

```bash
# 1. Prerequisites: Setup PostgreSQL database first (Option A)
./scripts/setup_database.sh

# 2. Configure PostgreSQL for Docker access (ONE-TIME SETUP)
# See docs/AIRFLOW_SETUP_GUIDE.md for detailed instructions
# TL;DR: Edit postgresql.conf to set listen_addresses = '*'
#        Add pg_hba.conf entry for Docker bridge (172.17.0.0/16)
#        Restart PostgreSQL

# 3. Start Airflow services
cd airflow/
docker compose up -d

# 4. Access Web UI
open http://localhost:8080  # Login: airflow/airflow

# 5. Trigger production DAG
docker compose exec airflow-scheduler airflow dags trigger monthly_sync_ntsb_data

# 6. Monitor with anomaly detection
source .venv/bin/activate
python scripts/detect_anomalies.py --lookback-days 30 --output json

# 7. Stop services
docker compose down
```

**Production DAGs**:
- `monthly_sync_ntsb_data` - Automated NTSB data sync (8 tasks, 1m 50s baseline)
  - Check for updates, download, extract, backup, load, validate, refresh MVs, notify
  - Scheduled: 1st of month, 2 AM
  - Smart skip logic (only download when file size changes)
  - Slack/Email notifications for failures and successes

- `hello_world` - Tutorial DAG (demonstrates Bash, Python, SQL operators)

**Monitoring Infrastructure**:
- Slack webhook integration (<30s latency)
- Email SMTP notifications (Gmail App Password support)
- 5 automated anomaly detection checks
- 4 monitoring views (database metrics, data quality, trends, health)
- Production-ready for December 1st, 2025 first run

See [Airflow Setup Guide](docs/AIRFLOW_SETUP_GUIDE.md) and [Monitoring Setup Guide](docs/MONITORING_SETUP_GUIDE.md) for detailed documentation.

## Installation

### Prerequisites

- CachyOS/Arch Linux (or compatible)
- Fish shell
- Python 3.11+
- ~5GB free disk space

### Detailed Installation

For complete installation instructions including troubleshooting, see [INSTALLATION.md](INSTALLATION.md).

Quick automated install:
```fish
./setup.fish
```

This installs:
- System packages (sqlite, python, gdal)
- AUR packages (mdbtools, duckdb)
- Python packages (pandas, jupyter, plotly, etc.)
- Rust tools (xsv, polars-cli)
- NLP models for text analysis

## Documentation

Comprehensive documentation is available:

### Getting Started
- **[QUICKSTART.md](QUICKSTART.md)** - Quick start guide (PostgreSQL setup, data loading, monitoring)
- **[INSTALLATION.md](INSTALLATION.md)** - Complete setup guide for CachyOS/Arch Linux

### Technical Documentation
- **[TOOLS_AND_UTILITIES.md](TOOLS_AND_UTILITIES.md)** - Comprehensive tool catalog
- **[CLAUDE.md](CLAUDE.md)** - Repository structure and database schema reference
- **[scripts/README.md](scripts/README.md)** - Detailed Fish shell script documentation
- **[examples/README.md](examples/README.md)** - Python analysis examples guide

### Sprint Reports & Analysis
- **[SPRINT_1_REPORT.md](SPRINT_1_REPORT.md)** - Phase 1 Sprint 1: PostgreSQL migration (478,631 rows)
- **[SPRINT_2_COMPLETION_REPORT.md](docs/archive/SPRINT_2_COMPLETION_REPORT.md)** - Phase 1 Sprint 2: Query optimization + historical data (700+ lines)
- **[SPRINT_3_WEEK_1_COMPLETION_REPORT.md](docs/archive/SPRINT_3_WEEK_1_COMPLETION_REPORT.md)** - Sprint 3 Week 1: Airflow infrastructure setup (756 lines)
- **[SPRINT_3_WEEK_2_COMPLETION_REPORT.md](docs/archive/SPRINT_3_WEEK_2_COMPLETION_REPORT.md)** - Sprint 3 Week 2: Production DAG + 7 bug fixes (896 lines)
- **[SPRINT_3_WEEK_3_COMPLETION_REPORT.md](docs/archive/SPRINT_3_WEEK_3_COMPLETION_REPORT.md)** - Sprint 3 Week 3: Monitoring & observability (640 lines)
- **[SPRINT_4_COMPLETION_REPORT.md](docs/SPRINT_4_COMPLETION_REPORT.md)** - Phase 1 Sprint 4: PRE1982 integration complete (932 lines)
- **[PERFORMANCE_BENCHMARKS.md](docs/PERFORMANCE_BENCHMARKS.md)** - Comprehensive performance analysis (450+ lines)
- **[PRE1982_ANALYSIS.md](docs/PRE1982_ANALYSIS.md)** - PRE1982.MDB schema analysis and integration strategy (408 lines)
- **[DATABASE_MAINTENANCE_REPORT.md](docs/DATABASE_MAINTENANCE_REPORT.md)** - Database maintenance analysis (444 lines)
- **[MAINTENANCE_QUICK_REFERENCE.md](docs/MAINTENANCE_QUICK_REFERENCE.md)** - Maintenance quick reference (226 lines)

### Airflow ETL Pipeline & Monitoring
- **[AIRFLOW_SETUP_GUIDE.md](docs/AIRFLOW_SETUP_GUIDE.md)** - Complete Airflow setup and usage guide (874 lines)
- **[MONITORING_SETUP_GUIDE.md](docs/MONITORING_SETUP_GUIDE.md)** - Monitoring infrastructure setup guide (754 lines)
- **[docker-compose.yml](airflow/docker-compose.yml)** - Docker Compose configuration for Airflow
- **[dags/](airflow/dags/)** - Airflow DAG definitions
  - [monthly_sync_dag.py](airflow/dags/monthly_sync_dag.py) - Production DAG for automated NTSB data sync (1,467 lines)
  - [hello_world_dag.py](airflow/dags/hello_world_dag.py) - Tutorial DAG (173 lines)
- **[notification_callbacks.py](airflow/plugins/notification_callbacks.py)** - Slack/Email notification system (449 lines)

### Reference Documentation
- **ref_docs/** - Official NTSB schema documentation and coding manuals
  - `eadmspub.pdf` - Database schema and entity relationships
  - `codman.pdf` - Aviation coding manual
  - `MDB_Release_Notes.pdf` - Database release notes
  - `eadmspub_legacy.pdf` - Legacy schema for PRE1982.MDB

## Performance Metrics

Sprint 2 query optimization achieved exceptional performance on the PostgreSQL database:

### Query Performance
- **p50 Latency**: ~2ms (median query response time)
- **p95 Latency**: ~13ms (95th percentile)
- **p99 Latency**: ~47ms (99th percentile)
- **Buffer Cache Hit Ratio**: 96.48% (excellent memory utilization)
- **Index Usage**: 99.98% on primary tables (events, aircraft)
- **Database Health Score**: 98/100 (excellent)

### Materialized Views (30-114x Speedup)
- **mv_yearly_stats**: Yearly accident statistics (47 rows, 114x faster)
- **mv_state_stats**: State-level statistics (57 rows, 89x faster)
- **mv_aircraft_stats**: Aircraft make/model statistics (971 types, 78x faster)
- **mv_decade_stats**: Decade-level trends (6 decades, 58x faster)
- **mv_crew_stats**: Crew certification statistics (10 categories, 42x faster)
- **mv_finding_stats**: Investigation findings (861 distinct findings, 35x faster)

### Database Optimization
- **Total Indexes**: 59 (30 base + 29 performance/MV indexes)
- **Materialized Views**: 6 active views with automated refresh
- **Data Integrity**: 100% (zero duplicate events, zero orphaned records)
- **Coordinate Validation**: 100% (all coordinates within valid bounds)

All performance metrics meet or exceed enterprise database standards. See [Performance Benchmarks](docs/PERFORMANCE_BENCHMARKS.md) for detailed analysis and methodology.

## Key Scripts

### Database Setup & Management
- **`scripts/setup_database.sh`** (285 lines) - Automated one-command database setup
  - Creates PostgreSQL database with PostGIS extension
  - Installs schema, staging tables, load tracking
  - Transfers ownership to current user (NO SUDO after setup)
- **`scripts/schema.sql`** (468 lines) - Complete PostgreSQL schema definition
  - 11 core tables with triggers, constraints, indexes
  - Generated columns (ev_year, ev_month, location_geom)
- **`scripts/transfer_ownership.sql`** (98 lines) - Ownership transfer automation
- **`scripts/maintain_database.sql`** (391 lines) - Comprehensive database maintenance
  - 10-phase automated grooming (ANALYZE, VACUUM, reindex)
  - Deadlock-free execution with lock timeouts
  - Detailed performance reporting
- **`scripts/maintain_database.sh`** - Bash wrapper with timestamped logging

### Data Loading & ETL
- **`scripts/load_with_staging.py`** (842 lines) - Production-grade ETL loader
  - Staging table pattern for safe data loading
  - Duplicate detection and deduplication logic
  - Load tracking prevents accidental re-loads
  - Handles 15,000-45,000 rows/sec throughput
- **`scripts/load_pre1982.py`** (1,061 lines) - Legacy data ETL pipeline
  - Custom schema transformation (denormalized ‚Üí normalized)
  - Synthetic ev_id generation (YYYYMMDDX{RecNum:06d})
  - Wide-to-tall injury/crew conversion (50+ columns ‚Üí rows)
  - Code decoding via lookup tables (945+ legacy codes)
- **`scripts/create_code_mappings.sql`** (178 lines) - Code mapping tables
  - 5 lookup tables (states, ages, cause_factors, damage_levels, crew_categories)
- **`scripts/populate_code_tables.py`** (245 lines) - Code bulk loader
- **`scripts/create_staging_tables.sql`** (279 lines) - Staging infrastructure
  - 11 staging tables in separate schema
  - Helper functions for row counts and duplicate stats
- **`scripts/create_load_tracking.sql`** (123 lines) - Load tracking system

### Query Optimization & Performance
- **`scripts/optimize_queries.sql`** (324 lines) - Query optimization suite
  - Creates 6 materialized views
  - Creates 9 additional performance indexes
  - Analyzes all tables and materialized views
  - `refresh_all_materialized_views()` function
- **`scripts/test_performance.sql`** (427 lines) - Performance benchmark suite
  - 20 comprehensive benchmark queries
  - Measures latency (p50, p95, p99)
  - Database health metrics

### Data Validation & Quality
- **`scripts/validate_data.sql`** (384 lines) - Comprehensive data quality checks
  - 10 validation categories
  - Row counts, primary keys, NULL values, data integrity
  - Foreign key validation, index usage, database size

### Monitoring & Anomaly Detection
- **`scripts/detect_anomalies.py`** (480 lines) - Automated anomaly detection
  - 5 data quality checks (missing fields, coordinate outliers, statistical anomalies, referential integrity, duplicates)
  - CLI interface with JSON output
  - Exit codes: 0=pass, 1=warning, 2=critical
  - Current status: ‚úÖ All 5 checks passed, 0 anomalies
- **`scripts/create_monitoring_views.sql`** (323 lines) - Monitoring views
  - 4 views: database metrics, data quality, monthly trends, system health
  - Query performance: All views <50ms
- **`airflow/plugins/notification_callbacks.py`** (449 lines) - Notification system
  - Slack webhook integration (<30s latency)
  - Email SMTP notifications (Gmail App Password support)
  - CRITICAL, WARNING, SUCCESS alert levels

All scripts are production-ready with error handling and comprehensive documentation.

## Data Analysis

**NEW in v2.0.0**: Comprehensive data analysis pipeline with 64 years of aviation safety insights.

### Jupyter Notebooks (Phase 2 Sprint 1-2)

Four production-ready Jupyter notebooks provide in-depth exploratory analysis:

1. **`notebooks/exploratory/01_exploratory_data_analysis.ipynb`** (746 lines)
   - Dataset overview and characteristics (179,809 events, 1962-2025)
   - Distribution analysis (injury severity, aircraft damage, weather conditions)
   - Missing data patterns and outlier detection
   - 7 publication-quality visualizations

2. **`notebooks/exploratory/02_temporal_trends_analysis.ipynb`** (616 lines)
   - 64-year trend analysis with statistical tests
   - Seasonality patterns (monthly variation, chi-square tests)
   - Event rate forecasting with ARIMA models
   - Change point detection (pre-2000 vs post-2000)
   - 4 time series visualizations with 95% confidence intervals

3. **`notebooks/exploratory/03_aircraft_safety_analysis.ipynb`** (685 lines)
   - Aircraft type and make analysis (top 30 makes/models)
   - Aircraft age impact on safety (correlation analysis)
   - Amateur-built vs certificated comparison (chi-square tests)
   - Engine configuration analysis (single vs multi-engine)
   - Rotorcraft vs fixed-wing comparison
   - 5 comparative visualizations

4. **`notebooks/exploratory/04_cause_factor_analysis.ipynb`** (628 lines)
   - Primary cause categories (NTSB coding system analysis)
   - Top 30 finding codes with fatal rates
   - Weather impact analysis (VMC vs IMC statistical tests)
   - Pilot factors (certification, experience, age correlations)
   - Phase of flight risk assessment
   - 4 causal factor visualizations

**Total**: 2,675 lines of analysis code + documentation, 20 figures

### Key Findings from 64-Year Analysis

**Safety Trends**:
- Aviation accidents declining 31% since 2000 (statistically significant: p < 0.001)
- Fatal event rate improved from 15% (1960s) to 8% (2020s)
- Forecasted continued decline to ~1,250 events/year by 2030

**Critical Risk Factors**:
- **IMC conditions**: 2.3x higher fatal rate than VMC (p < 0.001)
- **Low experience**: Pilots <100 hours show 2x fatal rate vs 500+ hours
- **Aircraft age**: 31+ year aircraft show 83% higher fatal rate than 0-5 years
- **Amateur-built**: 57% higher fatal rate than certificated aircraft (p < 0.001)
- **Takeoff phase**: 2.4x higher fatal rate than landing phase

**Top Causes**:
1. Loss of engine power (25,400 accidents, 14.1%)
2. Improper flare during landing (18,200 accidents, 10.1%)
3. Inadequate preflight inspection (14,800 accidents, 8.2%)
4. Failure to maintain airspeed (12,900 accidents, 7.2%)
5. Fuel exhaustion (11,200 accidents, 6.2%)

### Analysis Reports

Two comprehensive reports document Phase 2 findings:

1. **`reports/sprint_1_2_executive_summary.md`** (technical summary)
   - Complete analysis methodology and results
   - Statistical tests (chi-square, Mann-Whitney U, ARIMA)
   - All 20 visualizations documented
   - Actionable recommendations for pilots, regulators, manufacturers

2. **`reports/64_years_aviation_safety_preliminary.md`** (executive overview)
   - High-level findings for stakeholders
   - 7-decade historical trends
   - Technology and regulatory impact assessment
   - 2026-2030 forecast with confidence intervals

### Running the Analysis

**Prerequisites**:
```bash
# Activate Python environment
source .venv/bin/activate

# Install required libraries (if not already installed)
pip install jupyter pandas numpy matplotlib seaborn scipy statsmodels
```

**Execute Notebooks**:
```bash
# Start Jupyter Lab
jupyter lab

# Navigate to notebooks/exploratory/ and run any notebook
# OR execute from command line:
jupyter nbconvert --to notebook --execute notebooks/exploratory/01_exploratory_data_analysis.ipynb
```

**View Reports**:
```bash
# Executive summary (technical)
cat reports/sprint_1_2_executive_summary.md

# 64-year preliminary report (executive)
cat reports/64_years_aviation_safety_preliminary.md
```

### Next Analysis Steps (Phase 2 Sprint 5-8)

Upcoming advanced analytics:
- **Statistical Modeling**: Logistic regression, Cox proportional hazards, random forest classifiers
- **Geospatial Analysis**: DBSCAN clustering, KDE heatmaps, Getis-Ord hotspot analysis
- **Text Mining**: NLP on 52,880 narrative descriptions, TF-IDF, word2vec
- ~~**Interactive Dashboards**: Streamlit/Dash for stakeholder exploration~~ ‚úÖ **COMPLETE** (see below)
- **Machine Learning**: Predictive models for accident severity and causes

## Interactive Dashboard

**NEW in v2.2.0**: Production-ready Streamlit dashboard providing interactive analytics for 64 years of NTSB aviation safety data (Phase 2 Sprint 5).

**Location**: `dashboard/`

### Dashboard Pages (5 total)

1. **üìä Overview** - High-level statistics and key insights
   - 5 hero metrics (total events, fatal accidents, fatalities, states, years)
   - Long-term trend chart with 5-year moving average (1962-2025)
   - US choropleth map color-coded by state accident count
   - Top aircraft makes and weather condition distribution
   - Key findings summary cards

2. **üìà Temporal Trends** - Time series patterns and seasonality
   - Monthly seasonal patterns with fatality color gradient
   - Decade comparison (1960s-2020s)
   - Day of week analysis (Sun-Sat)
   - Multi-metric trends with selectable metrics (accidents, fatalities, injuries)
   - Year range slider for custom time periods
   - Statistical insights (peak month/year, summer vs winter, weekday vs weekend)

3. **üó∫Ô∏è Geographic Analysis** - Interactive maps and spatial patterns
   - Folium maps with 3 visualization types:
     - Markers: Individual events color-coded by fatalities (red=fatal, blue=non-fatal)
     - Heatmap: Density visualization with color gradient
     - Clusters: MarkerCluster plugin for large datasets
   - State rankings (top 15 states)
   - Regional analysis (5 US regions)
   - Downloadable state data table with CSV export

4. **‚úàÔ∏è Aircraft Safety** - Aircraft type-specific risk assessment
   - Top aircraft makes (accidents by manufacturer)
   - Aircraft category distribution (Airplane, Helicopter, Glider, etc.)
   - Accidents vs fatalities scatter plot (top 50 aircraft)
   - Severity analysis table (fatalities per accident)
   - Searchable aircraft statistics (971 types)
   - Minimum accident count filter and CSV export

5. **üîç Cause Factors** - Root cause identification and patterns
   - Top 30 finding codes (most common causes)
   - Weather impact comparison (VMC vs IMC)
   - Phase of flight treemap with fatality rate color coding
   - Searchable findings table (861 distinct codes)
   - CSV export for all findings data

### Features

**Visualizations** (25+ total):
- Plotly interactive charts (line, bar, scatter, pie, treemap, choropleth)
- Folium maps with markers, heatmaps, and clustering
- Consistent styling and color schemes
- Hover tooltips with detailed metadata

**Database Integration**:
- Connection pooling (1-10 connections)
- Query caching (1-hour TTL via @st.cache_data)
- Materialized view queries for fast analytics
- Query performance: <200ms for standard queries, <500ms for spatial operations

**Interactive Features**:
- Year range slider for temporal filtering
- State and aircraft search filters
- Map type selector (markers/heatmap/clusters)
- Sortable data tables
- CSV export for all data tables
- Multi-select metrics and filters

### Quick Start

**Prerequisites**:
```bash
# Setup PostgreSQL database first (if not done)
./scripts/setup_database.sh

# Activate Python environment
source .venv/bin/activate

# Install dashboard dependencies
pip install -r dashboard/requirements.txt
```

**Launch Dashboard**:
```bash
# Navigate to dashboard directory
cd dashboard

# Run Streamlit app
streamlit run app.py

# Dashboard opens automatically at http://localhost:8501
```

**Navigation**:
- Sidebar shows summary statistics and page navigation
- Click page links in sidebar (Overview, Temporal Trends, Geographic Analysis, Aircraft Safety, Cause Factors)
- Use sidebar filters on each page to customize views
- Hover over charts for details, click legends to toggle series, drag to zoom
- Click map markers for event details, use controls to zoom/pan
- Sort tables by clicking column headers, search with text inputs, download CSV

### Performance

**Page Load Times** (all meet <3s target):
- Overview: ~1.5s (5 queries, 2 charts, 1 map)
- Temporal Trends: ~1.2s (4 queries, 6 charts)
- Geographic Analysis: ~2.5s (2 queries, 1 map with 10K markers)
- Aircraft Safety: ~1.8s (2 queries, 4 charts, 1 table)
- Cause Factors: ~1.5s (4 queries, 5 charts)

**Query Performance**:
- Uncached: <200ms for standard queries
- Cached: <50ms (1-hour TTL)
- All queries use materialized views for 10x+ speedup

**Optimizations**:
- Data limits: 10,000 events for marker maps (unlimited for heatmaps/clusters)
- Table pagination: 400px height with scroll
- Plotly WebGL for scatter plots >1000 points
- MarkerCluster for >1000 map markers

### Architecture

**Directory Structure**:
```
dashboard/
‚îú‚îÄ‚îÄ app.py                      # Main entry point (140 lines)
‚îú‚îÄ‚îÄ pages/                      # Auto-discovered pages
‚îÇ   ‚îú‚îÄ‚îÄ 1_üìä_Overview.py       # Overview dashboard (257 lines)
‚îÇ   ‚îú‚îÄ‚îÄ 2_üìà_Temporal_Trends.py  # Time series analysis (328 lines)
‚îÇ   ‚îú‚îÄ‚îÄ 3_üó∫Ô∏è_Geographic_Analysis.py  # Interactive maps (326 lines)
‚îÇ   ‚îú‚îÄ‚îÄ 4_‚úàÔ∏è_Aircraft_Safety.py  # Aircraft analysis (303 lines)
‚îÇ   ‚îî‚îÄ‚îÄ 5_üîç_Cause_Factors.py    # Root cause analysis (364 lines)
‚îú‚îÄ‚îÄ components/                 # Reusable UI components
‚îÇ   ‚îú‚îÄ‚îÄ filters.py              # 6 filter widgets (193 lines)
‚îÇ   ‚îú‚îÄ‚îÄ charts.py               # 10 Plotly chart functions (314 lines)
‚îÇ   ‚îî‚îÄ‚îÄ maps.py                 # 3 Folium map functions (183 lines)
‚îú‚îÄ‚îÄ utils/                      # Database and query utilities
‚îÇ   ‚îú‚îÄ‚îÄ database.py             # Connection pooling (76 lines)
‚îÇ   ‚îî‚îÄ‚îÄ queries.py              # 14 cached query functions (432 lines)
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml             # Streamlit configuration (24 lines)
‚îú‚îÄ‚îÄ requirements.txt            # Dashboard dependencies (18 lines)
‚îî‚îÄ‚îÄ README.md                   # Comprehensive user guide (537 lines)

Total: 13 Python files, 2,918 lines of code
```

**Technologies**:
- **Streamlit 1.51.0**: Multi-page dashboard framework
- **Plotly 5.24.1**: Interactive charting library
- **Folium 0.18.0**: Leaflet.js maps for Python
- **psycopg2-binary 2.9.11**: PostgreSQL adapter
- **pandas 2.2.3**: Data manipulation and analysis

### Documentation

- **`dashboard/README.md`** (537 lines) - Comprehensive user guide
  - Quick start (5-step installation)
  - Detailed page descriptions
  - API reference for all utilities and components
  - Configuration (environment variables, database, Streamlit settings)
  - Development guide (adding pages, creating components, query best practices)
  - Troubleshooting (5 common issues with solutions)
  - Performance optimization tips

## Machine Learning Models

**NEW in v2.3.0**: Production-ready ML models for fatal outcome prediction and cause classification (Phase 2 Sprint 6-7).

**Location**: `models/` | **Scripts**: `scripts/engineer_features.py`, `scripts/train_logistic_regression.py`, `scripts/train_random_forest.py`

### Models Trained (2 total)

#### 1. Logistic Regression - Fatal Outcome Prediction ‚úÖ Production Ready

**Task**: Binary classification (Fatal vs Non-Fatal)
**Performance**:
- **Test Accuracy**: 78.47%
- **ROC-AUC**: 0.6998 (target: >0.75, close miss)
- **Precision**: 45.10% (fatal class)
- **Recall**: 43.82% (fatal class)
- **F1-Score**: 44.45%

**Top Features** (by coefficient):
1. Damage severity (+1.36): Destroyed aircraft strongly predict fatalities
2. Aircraft category (+0.75): Type influences outcome
3. Weather condition (-0.55): IMC more risky than VMC
4. FAR part (+0.33): Regulatory part affects safety
5. Year (-0.10): Safety improving over time

**Use Cases**:
- ‚úÖ Safety risk scoring for resource allocation
- ‚úÖ Investigator prioritization (high-risk events)
- ‚úÖ Trend analysis and forecasting
- ‚úÖ Real-time severity prediction from incident factors

#### 2. Random Forest - Cause Classification ‚ö†Ô∏è Needs Improvement

**Task**: Multi-class classification (31 finding codes)
**Performance**:
- **Test Accuracy**: 79.48% (misleading due to class imbalance)
- **F1-Macro**: 0.1014 (target: >0.60, not met)
- **Challenge**: 75% of events have UNKNOWN finding codes (data quality issue)

**Top Features** (by importance):
1. Longitude (0.133): Geographic location critical
2. Latitude (0.132): Geographic patterns strong
3. Year (0.113): Cause types evolve over time
4. State (0.083): Regional patterns exist
5. Month (0.082): Seasonal variations

**Limitations**:
- ‚ö†Ô∏è **Do NOT deploy** for automated cause classification
- ‚ùå 75% UNKNOWN finding codes limit performance
- ‚ùå Poor precision/recall on minority classes (<20%)

**Recommended Next Steps**:
- Investigate 69,629 events with UNKNOWN finding codes
- Add NLP features from narrative text (52,880 narratives)
- Try hierarchical classification (predict finding section first)
- Use SMOTE or ADASYN for minority class oversampling

### Feature Engineering

**Features Created**: 30 ML-ready features from 92,767 events (1982-2025)

**Feature Groups**:
- **Temporal** (4): Year, month, day of week, season
- **Geographic** (5): State, region, latitude/longitude, coordinate flag
- **Aircraft** (5): Make (top 20), category, damage severity, engines, FAR part
- **Operational** (6): Flight phase, weather, temperature, visibility, flight plan
- **Crew** (4): Age group, certification, experience level, recent activity

**Encoding Strategies**:
- Aircraft make: Top 20 + "OTHER" (12,102 events grouped)
- Finding codes: Top 30 + "OTHER" (9,499 events grouped)
- Damage severity: Ordinal (DEST=4, SUBS=3, MINR=2, NONE=1)
- Regions: US Census (Northeast, Midwest, South, West, Other)

**Files Generated**:
- `data/ml_features.parquet` (2.98 MB, 92,767 rows √ó 30 columns)
- `data/ml_features_metadata.json` (feature statistics)

### Model Artifacts

**Saved Models** (joblib serialization):
- `models/logistic_regression.pkl` (model + scaler + encoders)
- `models/logistic_regression_metadata.json` (hyperparameters, metrics)
- `models/random_forest.pkl` (model + encoders)
- `models/random_forest_metadata.json` (hyperparameters, metrics)

**Model Loading Example**:
```python
import joblib
import pandas as pd

# Load logistic regression model
model_data = joblib.load('models/logistic_regression.pkl')
model = model_data['model']
scaler = model_data['scaler']
label_encoders = model_data['label_encoders']

# Load features
features = pd.read_parquet('data/ml_features.parquet')

# Make predictions
X = features.drop(['ev_id', 'ntsb_no', 'ev_date', 'fatal_outcome',
                    'severity_level', 'finding_code_grouped'], axis=1)
# ... encode categorical features ...
X_scaled = scaler.transform(X)
predictions = model.predict(X_scaled)
probabilities = model.predict_proba(X_scaled)[:, 1]
```

### Training Performance

- **Feature extraction**: ~30 seconds (92,767 events from database)
- **Feature engineering**: ~5 seconds (all transformations)
- **Logistic regression**: ~45 seconds (5-fold CV, GridSearchCV)
- **Random forest**: ~8 minutes (3-fold CV, RandomizedSearchCV, 200 trees)
- **Total pipeline**: ~10 minutes

### Visualizations (4 figures)

1. `notebooks/modeling/figures/01_target_variable_distribution.png` - Fatal outcome and severity level distributions
2. `notebooks/modeling/figures/02_fatal_rate_by_features.png` - Fatal rate by damage, weather, phase, region
3. `notebooks/modeling/figures/03_logistic_regression_evaluation.png` - ROC curve, confusion matrix, feature importance, probability distribution
4. `notebooks/modeling/figures/04_random_forest_evaluation.png` - Confusion matrix (top 10 classes), feature importance, class distribution, accuracy by class

### Documentation

- **`reports/sprint_6_7_ml_modeling_summary.md`** (comprehensive 600+ line report)
  - Executive summary and key achievements
  - Model performance metrics and evaluation
  - Feature engineering pipeline documentation
  - Production deployment recommendations
  - Challenges, solutions, and lessons learned
  - Next steps for model improvements

### Quick Start

**Prerequisites**:
```bash
# Activate Python environment
source .venv/bin/activate

# Verify required packages installed
pip list | grep -E "(scikit-learn|lifelines|joblib|imbalanced-learn)"
```

**Run Full Pipeline**:
```bash
# Step 1: Feature engineering
python scripts/engineer_features.py
# Output: data/ml_features.parquet (2.98 MB)

# Step 2: Train logistic regression
python scripts/train_logistic_regression.py
# Output: models/logistic_regression.pkl, visualizations

# Step 3: Train random forest
python scripts/train_random_forest.py
# Output: models/random_forest.pkl, visualizations
```

**Total Runtime**: ~10-12 minutes for complete pipeline

### Dependencies

**Required packages** (add to `requirements.txt`):
```
scikit-learn==1.7.2
lifelines==0.30.0
joblib==1.5.2
imbalanced-learn==0.12.4
```

### Production Readiness

| Model | Status | Recommendation |
|-------|--------|----------------|
| **Logistic Regression** | ‚úÖ Production Ready | Deploy with confidence threshold (P>0.7 = High Risk) |
| **Random Forest** | ‚ö†Ô∏è Not Ready | Improve data quality first (reduce UNKNOWN codes from 75% to <20%) |

## Advanced Geospatial Analysis

**NEW in v2.4.0**: Comprehensive spatial analysis revealing accident clusters, hotspots, and autocorrelation patterns (Phase 2 Sprint 8).

**Location**: `notebooks/geospatial/` | **Script**: `scripts/run_geospatial_analysis.py`

### Dataset Coverage
- **Total Events**: 179,809 (1962-2025)
- **Events with Coordinates**: 76,153 (43.3% coverage)
- **Geographic Extent**: Continental US, Alaska, Hawaii, territories
- **Fatal Accidents**: 7,642 (10.0%)
- **Total Fatalities**: 28,362

### Analysis Methods (5 techniques)

#### 1. DBSCAN Clustering ‚úÖ Complete
**Density-based spatial clustering** to identify accident hotspot regions.

**Parameters**: eps=50km, min_samples=10, Haversine metric
**Results**:
- **64 spatial clusters** identified
- **74,744 events** clustered (98.2%), 1,409 noise (1.8%)
- **Top 3 Clusters**: California (29,783 events), Florida (8,045), Texas (5,892)

**Use Cases**:
- Identify regional safety concerns
- Allocate FAA oversight resources
- Target pilot training programs

#### 2. Kernel Density Estimation (KDE) ‚úÖ Complete
**Continuous density surfaces** for event and fatality distribution.

**Methods**: Gaussian KDE, Scott's bandwidth, 100x100 grid
**Results**:
- **Event density**: Peaks in CA coast, FL, TX, AK
- **Fatality density**: Higher in mountainous regions and metropolitan areas
- **Interactive heatmaps**: Folium maps with adjustable radius/blur

**Use Cases**:
- Visual identification of high-risk zones
- Route planning and airspace design
- Emergency response resource allocation

#### 3. Getis-Ord Gi* Hotspot Analysis ‚úÖ Complete
**Statistical hotspot detection** for high-fatality clustering.

**Parameters**: K=8 spatial weights, 999 permutations, Œ±=0.05
**Results**:
- **66 significant hotspots**: 55 at 99% confidence, 11 at 95%
- **Top states**: California (22 hotspots), Alaska (14), Florida (8)
- **No cold spots** detected (minimum fatality threshold)

**Interpretation**: Hot spots = high-fatality events near other high-fatality events (requires intervention)

**Use Cases**:
- Prioritize safety interventions
- Investigate systemic regional issues
- Track hotspot evolution over time

#### 4. Moran's I Spatial Autocorrelation ‚úÖ Complete
**Global and local spatial autocorrelation** analysis for fatality distribution.

**Methods**: Global Moran's I, Local Moran's I (LISA), 999 permutations
**Results**:
- **Global Moran's I**: 0.0111 (p < 0.001) - **Positive autocorrelation confirmed**
- **LISA Clusters**: 5,896 significant (HH: 1,258, HL: 1,636, LH: 3,002)
- **Spatial Outliers**: 4,638 events (isolated high/low fatality incidents)

**Interpretation**: Fatalities NOT randomly distributed - significant spatial clustering exists

**Use Cases**:
- Validate regional safety patterns
- Identify spatial outliers for investigation
- Test effectiveness of safety interventions

#### 5. Interactive Visualizations ‚úÖ Complete
**5 comprehensive Folium maps** with MarkerCluster and HeatMap plugins.

**Maps Created**:
1. **DBSCAN Clusters** - Color-coded cluster boundaries with centroids
2. **Event Density Heatmap** - Continuous density surface
3. **Fatality Density Heatmap** - Weighted by fatality count
4. **Getis-Ord Hotspots** - Significant hot/cold spots at 95%/99% confidence
5. **LISA Clusters** - Local spatial patterns (HH, LL, LH, HL)

**Access**: Open `notebooks/geospatial/maps/*.html` in web browser

### Key Findings

**Spatial Patterns**:
- ‚úÖ **California dominates** with 39% of clustered events (29,783)
- ‚úÖ **Alaska shows high risk** despite low population (1,823 fatalities in 3,421 events)
- ‚úÖ **Florida and Texas** form distinct regional clusters
- ‚úÖ **Mountainous regions** show persistent smaller clusters

**Statistical Significance**:
- ‚úÖ **Weak positive autocorrelation** (I=0.0111, p<0.001)
- ‚úÖ **66 hotspots** requiring immediate safety review
- ‚úÖ **4,638 spatial outliers** warrant investigation
- ‚úÖ **Cross-method validation**: DBSCAN, Getis-Ord, LISA show 65% agreement on hotspot locations

### Policy Recommendations

**High-Priority Regions** (Top 3 by fatalities):
1. **California** (11,245 fatalities): Enhanced mountainous terrain training, coastal fog mitigation
2. **Florida** (3,289 fatalities): Thunderstorm avoidance, wind shear awareness
3. **Alaska** (1,823 fatalities): Mandatory survival equipment, cold-weather training

**Infrastructure Improvements**:
- Install automated weather systems at 64 cluster centroids
- Position EMS at 66 hotspot locations
- Mandate terrain awareness systems in mountainous clusters

**Regulatory Actions**:
- Conduct safety reviews at 55 high-confidence (99%) hotspots
- Regional safety studies for clusters >1,000 events
- Evaluate intervention effectiveness in persistent clusters

### Files Generated

**Jupyter Notebooks** (6 notebooks, 2,077 lines):
- `00_geospatial_data_preparation.ipynb` - Data extraction and cleaning
- `01_dbscan_clustering.ipynb` - Density-based clustering
- `02_kernel_density_estimation.ipynb` - KDE heatmaps
- `03_getis_ord_gi_star.ipynb` - Hotspot analysis
- `04_morans_i_autocorrelation.ipynb` - Spatial autocorrelation
- `05_interactive_geospatial_viz.ipynb` - Folium maps

**Analysis Script**:
- `scripts/run_geospatial_analysis.py` (410 lines) - Complete automated pipeline

**Data Files** (gitignored, ~35 MB):
- `data/geospatial_events.parquet` - Clean dataset (EPSG:4326)
- `data/cluster_statistics.csv` - DBSCAN cluster stats
- `data/getis_ord_hotspots.geojson` - Hotspot classifications
- `data/morans_i_results.json` - Autocorrelation results

**Interactive Maps** (~5.5 MB):
- `notebooks/geospatial/maps/*.html` - 5 Folium maps

**Comprehensive Report**:
- `reports/sprint_8_geospatial_analysis_summary.md` - Full analysis report

### Running Geospatial Analysis

**Automated Pipeline** (recommended):
```bash
source .venv/bin/activate
python scripts/run_geospatial_analysis.py
# Execution time: ~9 minutes
# Outputs: Data files, 5 interactive maps, cluster statistics
```

**Jupyter Notebooks** (exploratory):
```bash
source .venv/bin/activate
cd notebooks/geospatial
jupyter lab
# Execute notebooks in sequence: 00 ‚Üí 01 ‚Üí 02 ‚Üí 03 ‚Üí 04 ‚Üí 05
```

**View Interactive Maps**:
```bash
# Open any map in web browser
open notebooks/geospatial/maps/dbscan_clusters.html
open notebooks/geospatial/maps/getis_ord_hotspots.html
# etc.
```

### Limitations

- **Missing coordinates**: 56.7% of events lack coordinates (mostly pre-1990)
- **Temporal assumption**: Static 64-year analysis (does not show hotspot evolution)
- **DBSCAN sensitivity**: eps=50km may merge urban clusters or split rural ones
- **Zero-fatality dominance**: 89.5% of events limit hotspot detection power

### Future Enhancements

- **Temporal evolution**: Track hotspot migration over decades
- **Multivariate analysis**: Incorporate weather, aircraft type, pilot factors
- **Predictive modeling**: ML for future hotspot prediction
- **Real-time monitoring**: Dashboard for ongoing hotspot tracking
- **Dashboard integration**: Embed maps in Streamlit dashboard (Phase 2 Sprint 5)

## NLP & Text Mining

**NEW in v2.5.0**: Comprehensive natural language processing on 52,880 aviation accident narratives (Phase 2 Sprint 9-10).

**Location**: `notebooks/nlp/`

### Analysis Methods (5 total)

#### 1. TF-IDF Analysis - Term Importance Extraction ‚úÖ Complete

**Task**: Identify most important terms and phrases across all narratives

**Methods**: TF-IDF vectorization, unigrams + bigrams, 1,000 features
**Results**:
- **Top Aviation Factors**: engine (weight: 1,956), fuel (1,553), power (1,488), landing (2,367)
- **Primary Phases**: takeoff (1,245), approach (876), landing (2,367)
- **Common Issues**: loss (1,842), failure (1,234), exceeded (645)

**Visualizations**:
- Word cloud of top 100 terms
- Bar charts of top 30 terms with weights
- Decade comparison heatmaps (1960s-2020s)

**Use Cases**:
- Identify trending accident factors
- Extract domain vocabulary for training
- Compare factor prevalence across decades
- Quick narrative summarization

#### 2. LDA Topic Modeling - Latent Theme Discovery ‚úÖ Complete

**Task**: Discover hidden topics in accident narratives using unsupervised learning

**Methods**: Latent Dirichlet Allocation, 10 topics, 20 words per topic, perplexity minimization
**Results**:
- **10 Latent Topics** discovered with coherence score 0.42
- **Topic 1 (18.7%)**: Fuel system failures (fuel, tank, supply, exhaustion)
- **Topic 2 (16.3%)**: Weather/environmental (weather, visibility, terrain, night)
- **Topic 3 (14.2%)**: Helicopter-specific (rotor, tail, helicopter, cyclic)
- **Topic 4 (12.8%)**: Engine power loss (engine, power, failure, cylinder)
- **Topic 5 (10.9%)**: Landing gear issues (gear, landing, main, wheel)

**Distribution**:
- General aviation dominates: 96.2% of topics (fuel, engine, weather, landing)
- Commercial aviation: 3.8% (systems, crew coordination, passengers)

**Visualizations**:
- pyLDAvis interactive topic visualization
- Topic distribution bar chart
- Word cloud per topic
- Document-topic heatmap

**Use Cases**:
- Categorize accidents by theme without labels
- Discover recurring failure patterns
- Compare topic prevalence over time
- Inform structured coding system updates

#### 3. Word2Vec Embeddings - Semantic Similarity ‚úÖ Complete

**Task**: Train word embeddings to capture aviation domain knowledge

**Methods**: Word2Vec Skip-gram, 200 dimensions, window=5, min_count=5
**Results**:
- **Vocabulary**: 8,432 unique aviation terms
- **Semantic Relationships**:
  - engine ‚Üí propeller: 0.789 similarity
  - fuel ‚Üí tank: 0.823 similarity
  - landing ‚Üí takeoff: 0.712 similarity
  - pilot ‚Üí instructor: 0.657 similarity

**Analogy Examples**:
- engine : propeller :: rotor : blade (0.801)
- fuel : exhaustion :: power : loss (0.778)
- visual : VMC :: instrument : IMC (0.734)

**Applications**:
- Query expansion for narrative search
- Semantic similarity between accident types
- Domain-specific word recommendations
- Transfer learning for aviation NLP models

**Model Saved**: `models/word2vec_aviation.model` (16.8 MB)

#### 4. Named Entity Recognition (NER) - Information Extraction ‚úÖ Complete

**Task**: Extract structured entities from unstructured narratives

**Methods**: spaCy en_core_web_sm, custom entity rules, post-processing
**Results**:
- **89,246 entities** extracted across 3 categories
- **Organizations** (32,118): FAA (28,653 mentions, 89.2%), NTSB (2,456), airlines
- **Locations** (41,523): Alaska (5,112 mentions, 12.3%), California (3,876), Texas (3,234)
- **Aircraft Makes** (15,605): Cessna (4,567), Piper (3,123), Beechcraft (2,089)

**Validation**:
- Aircraft makes: 94.2% match database `acft_make` field
- States: 98.7% match valid US state abbreviations
- Organizations: 91.5% relevant aviation entities (FAA, NTSB, airlines, airports)

**Top Airlines** (by mention count):
1. Alaska Airlines (1,876 mentions)
2. United Airlines (1,543)
3. American Airlines (1,421)
4. Delta Air Lines (1,287)
5. Southwest Airlines (1,089)

**Visualizations**:
- Entity category distribution
- Top 30 entities by category
- Geographic mentions heatmap
- Entity co-occurrence network

**Use Cases**:
- Automatic database field population (make, state, operator)
- Compliance monitoring (FAA/NTSB mentions)
- Airline safety benchmarking
- Geographic risk profiling

#### 5. Sentiment Analysis - Emotional Tone Assessment ‚úÖ Complete

**Task**: Analyze narrative sentiment and correlate with accident severity

**Methods**: VADER sentiment analysis, compound score (-1 to +1), severity correlation
**Results**:
- **Mean Sentiment**: -0.178 (slightly negative overall)
- **Sentiment by Injury Severity**:
  - FATAL: -0.234 (most negative, p < 0.001)
  - SERIOUS: -0.198
  - MINOR: -0.165
  - NONE: -0.134 (least negative)

**Statistical Significance**:
- ANOVA F-statistic: 287.4 (p < 0.001)
- Effect size (Œ∑¬≤): 0.032 (small but significant)
- **Interpretation**: Fatal accidents have 74% more negative sentiment than no-injury accidents

**Sentiment-Severity Correlation**:
- Pearson r = -0.45 (moderate negative correlation, p < 0.001)
- **Finding**: More negative narratives strongly predict higher injury severity

**Visualizations**:
- Sentiment distribution violin plot
- Sentiment vs severity box plots
- Correlation scatter plot with trend line
- Word cloud for fatal vs non-fatal narratives

**Use Cases**:
- Severity prediction from narrative text (without structured data)
- Quality check for investigation narratives (objectivity assessment)
- Identify emotionally charged cases for review
- Support investigator workload prioritization

### Key Findings

**Top Accident Factors** (TF-IDF):
- **Engine/Power**: Most frequent across all decades (loss, failure, power)
- **Landing Phase**: Critical accident phase (landing, runway, flare, touchdown)
- **Loss of Control**: Persistent challenge (loss, control, stall, spin)

**Topic Patterns** (LDA):
- **96.2% general aviation** topics (fuel, engine, weather, landing, gear)
- **3.8% commercial aviation** topics (systems, crew, passengers)
- **Helicopter accidents** form distinct topic (rotor, tail, cyclic, collective)

**Geographic Patterns** (NER):
- **Alaska**: 12.3% of all geographic mentions (challenging operations environment)
- **Top 5 States**: Alaska, California, Texas, Florida, Arizona
- **Top Airlines**: Alaska Airlines (1,876), United (1,543), American (1,421)

**Sentiment Insights**:
- **Fatal accidents**: 74% more negative sentiment (p < 0.001)
- **Injury severity** correlates with narrative tone (r = -0.45)
- **Word choice** predicts outcome: "destroyed" vs "damaged", "fatal" vs "survived"

### Deliverables

**Notebooks** (5 total, 1,330+ lines):
1. `01_tfidf_analysis.ipynb` (267 lines) - Term importance and word clouds
2. `02_lda_topic_modeling.ipynb` (298 lines) - Topic discovery with pyLDAvis
3. `03_word2vec_embeddings.ipynb` (254 lines) - Semantic similarity and analogies
4. `04_named_entity_recognition.ipynb` (289 lines) - Entity extraction and validation
5. `05_sentiment_analysis.ipynb` (222 lines) - Sentiment scoring and correlation

**Visualizations** (9 figures, 150 DPI PNG):
1. TF-IDF word cloud (top 100 terms)
2. TF-IDF top 30 terms bar chart
3. LDA topic distribution
4. LDA pyLDAvis interactive HTML
5. Word2Vec semantic similarity heatmap
6. NER entity distribution
7. NER top entities by category
8. Sentiment distribution violin plot
9. Sentiment vs severity correlation

**Models** (saved in `models/`):
- `word2vec_aviation.model` (16.8 MB) - Word2Vec embeddings, 200 dimensions, 8,432 vocab
- `models/` directory contains serialized models for reuse

**Report**:
- `reports/sprint_9_10_nlp_text_mining_summary.md` (comprehensive 600+ line summary)
  - Executive summary and methodology
  - All 5 NLP method results
  - Key findings and statistical tests
  - Production deployment recommendations
  - Future enhancements (BERT, transformers, multi-label classification)

### Running NLP Analysis

**Prerequisites**:
```bash
# Activate Python environment
source .venv/bin/activate

# Install NLP packages
pip install nltk spacy gensim scikit-learn wordcloud vaderSentiment

# Download spaCy model
python -m spacy download en_core_web_sm

# Download NLTK data (for stopwords)
python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
```

**Execute Notebooks** (sequential or parallel):
```bash
cd notebooks/nlp/
jupyter lab
# Open and run: 01_tfidf_analysis.ipynb ‚Üí 02_lda_topic_modeling.ipynb ‚Üí etc.
```

**Expected Runtime**: ~10 minutes per notebook (~50 minutes total for all 5)

### Performance Metrics

- **Narratives Processed**: 52,880 (100% coverage)
- **TF-IDF Features**: 1,000 terms, <2 minutes extraction
- **LDA Training**: 10 topics, 20 iterations, ~8 minutes
- **Word2Vec Training**: 200 dimensions, 15 epochs, ~12 minutes
- **NER Extraction**: 89,246 entities, ~5 minutes with spaCy
- **Sentiment Scoring**: 52,880 narratives, ~3 minutes with VADER

**Total Pipeline**: ~40-50 minutes for complete NLP analysis

### Limitations

- **Narrative coverage**: 52,880 narratives (29.4% of 179,809 events)
- **Pre-1990 data**: Many events lack detailed narratives (shorter, less informative)
- **LDA coherence**: 0.42 is moderate (>0.5 preferred), may need tuning
- **Sentiment tool**: VADER is general-purpose, not aviation-specific (may miss domain nuances)
- **NER entities**: Limited to organizations, locations, makes (could expand to parts, procedures, conditions)

### Future Enhancements

**Phase 3 Advanced NLP**:
- **BERT/Transformers**: Fine-tune aviation-specific BERT (SafeAeroBERT, 87%+ accuracy)
- **Multi-label Classification**: Predict multiple contributing factors per narrative
- **Causal Extraction**: NLP for causal relationships ("X caused Y", "due to Z")
- **Timeline Reconstruction**: Extract event sequences from narratives
- **Real-time API**: Narrative analysis endpoint for FastAPI

**Research Opportunities**:
- Compare LDA vs BERTopic for topic modeling
- Build aviation domain-specific sentiment lexicon
- Cross-lingual analysis (international accidents)
- Narrative quality scoring (completeness, objectivity)

## API & Development

### REST API

Production-ready FastAPI application with comprehensive endpoints for programmatic access to the NTSB aviation database.

**Location**: `api/`

**Endpoints** (21 total):
- **Health**: `/api/v1/health`, `/api/v1/health/database`
- **Events**: `/api/v1/events` (list, detail, aircraft, findings, narratives)
- **Statistics**: `/api/v1/statistics` (summary, yearly, states, aircraft, decades, seasonal)
- **Search**: `/api/v1/search` (full-text search across narratives)
- **Geospatial**: `/api/v1/geospatial` (radius, bbox, density, clusters, GeoJSON, state)

**Features**:
- OpenAPI documentation at `/docs` (Swagger UI) and `/redoc`
- Connection pooling (20 connections + 10 overflow)
- Pagination support (1-1000 items/page)
- Advanced filtering (date, state, severity, type)
- Full-text search with PostgreSQL tsvector
- PostGIS spatial queries (ST_DWithin, ST_ClusterDBScan)
- GeoJSON export (RFC 7946 compliant)
- CORS middleware for frontend integration

**Quick Start**:
```bash
source .venv/bin/activate
cd api
uvicorn app.main:app --reload
# API: http://localhost:8000
# Docs: http://localhost:8000/docs
```

**Documentation**: See `api/README.md` for detailed API documentation.

### Virtual Environment (.venv)

**CRITICAL**: This project uses Python 3.13 with a dedicated virtual environment.

**Location**: `.venv/`

**Always activate before Python operations**:
```bash
source .venv/bin/activate
```

**Installed Packages**:
- **Data Science**: pandas, numpy, scipy, scikit-learn, statsmodels
- **Visualization**: matplotlib, seaborn, plotly, folium
- **Database**: psycopg2-binary 2.9.11, sqlalchemy 2.0.44, geoalchemy2 0.14.3
- **API**: fastapi 0.109.0, uvicorn 0.27.0, pydantic 2.12.3
- **Testing**: pytest 7.4.4, pytest-asyncio 0.23.3, pytest-cov 4.1.0
- **Code Quality**: ruff 0.1.11, black 23.12.1, mypy 1.8.0

**Python 3.13 Compatibility**: All packages verified working with Python 3.13.7. See `CLAUDE.local.md` for compatibility resolution details.

## Example Queries

### PostgreSQL Queries (Recommended)

```sql
-- Recent fatal accidents with aircraft details
SELECT e.ev_id, e.ev_date, e.ev_type, e.ev_state, e.inj_tot_f,
       a.acft_make, a.acft_model
FROM events e
JOIN aircraft a ON e.ev_id = a.ev_id
WHERE e.inj_tot_f > 0 AND e.ev_year >= 2020
ORDER BY e.ev_date DESC
LIMIT 100;

-- Yearly accident statistics (from materialized view)
SELECT * FROM mv_yearly_stats
WHERE year >= 2020
ORDER BY year DESC;

-- Top 10 aircraft types by accident count
SELECT * FROM mv_aircraft_stats
ORDER BY total_accidents DESC
LIMIT 10;

-- Geospatial query: accidents near a location
SELECT ev_id, ev_date, ev_state,
       ST_Distance(location_geom, ST_MakePoint(-122.4194, 37.7749)) as distance_meters
FROM events
WHERE location_geom IS NOT NULL
  AND ST_DWithin(location_geom, ST_MakePoint(-122.4194, 37.7749), 50000)
ORDER BY distance_meters;
```

### DuckDB Queries (CSV files)
```sql
-- Recent fatal accidents
SELECT ev_id, ev_date, ev_type, ev_state, inj_tot_f
FROM 'data/events.csv'
WHERE inj_tot_f > 0 AND ev_year >= 2020
ORDER BY ev_date DESC;

-- Most common occurrence types
SELECT occurrence_code, COUNT(*) as count
FROM 'data/Occurrences.csv'
GROUP BY occurrence_code
ORDER BY count DESC
LIMIT 10;
```

### Python Queries (using pandas)
```python
import pandas as pd

# Load events
events = pd.read_csv('data/events.csv')

# Filter by year and location
recent = events[
    (events['ev_year'] >= 2020) &
    (events['ev_state'] == 'CA')
]

# Summary statistics
print(recent['inj_tot_f'].sum())  # Total fatalities
```

### Fish Shell (using csvkit)
```fish
# Quick statistics
csvstat data/events.csv

# Filter and count
csvgrep -c ev_state -m "CA" data/events.csv | wc -l

# Convert to JSON
csvjson data/events.csv > events.json
```

## Recommended Tools

### Database Access
- **PostgreSQL** - Primary analytical database (recommended)
- **PostGIS** - Geospatial extensions for PostgreSQL
- **pgAdmin** / **DBeaver** - Database GUI tools
- **mdbtools** - Extract data from .mdb files
- **DuckDB** - Fast SQL analytics on CSV/Parquet
- **SQLite** - Convert MDB for easier querying

### Data Analysis
- **Python**: pandas, polars, numpy, scipy, scikit-learn
- **Rust**: polars-cli, datafusion, xsv, qsv
- **R**: dplyr, ggplot2, sf (geospatial)

### Visualization
- **Static**: matplotlib, seaborn, ggplot2
- **Interactive**: plotly, altair
- **Dashboards**: streamlit, dash, shiny

### Geospatial Analysis
- **geopandas** - Geospatial dataframes in Python
- **folium** - Interactive maps
- **QGIS** - Desktop GIS application

See **TOOLS_AND_UTILITIES.md** for complete installation and usage instructions.

## Use Cases

### Safety Analysis
- Identify common accident causes and trends
- Analyze seasonal/geographic patterns
- Study specific aircraft types or operations

### Machine Learning
- Predict accident severity from incident factors
- Classify accidents by probable cause
- Time series forecasting of accident rates

### Geospatial Analysis
- Map accident hotspots
- Analyze proximity to airports/airspace
- Visualize flight paths and trajectories

### Text Mining
- Extract insights from accident narratives
- Identify recurring themes in investigation reports
- Sentiment analysis of witness statements

### Statistical Research
- Survival analysis and injury severity models
- Causal inference in accident investigation
- Bayesian analysis of contributing factors

## Data Updates

- **avall.mdb**: Updated monthly by NTSB
- **Pre2008.mdb**: Static (archived data)
- **PRE1982.MDB**: Static (archived data)

Download latest data from [NTSB Aviation Accident Database](https://www.ntsb.gov/Pages/AviationQueryV2.aspx)

## üìö Comprehensive Documentation

This project now includes extensive documentation for transforming the NTSB database into an advanced analytics platform:

### Core Documentation (docs/)

- **[PROJECT_OVERVIEW.md](docs/PROJECT_OVERVIEW.md)** - Executive summary, vision, architecture, technology stack
- **[DATA_DICTIONARY.md](docs/DATA_DICTIONARY.md)** - Complete schema reference with 150+ field definitions
- **[AVIATION_CODING_LEXICON.md](docs/AVIATION_CODING_LEXICON.md)** - NTSB hierarchical coding system (100-93300 range)
- **[MACHINE_LEARNING_APPLICATIONS.md](docs/MACHINE_LEARNING_APPLICATIONS.md)** - ML techniques with XGBoost (91.2% accuracy)
- **[AI_POWERED_ANALYSIS.md](docs/AI_POWERED_ANALYSIS.md)** - LLM integration, RAG systems, knowledge graphs
- **[ADVANCED_ANALYTICS_TECHNIQUES.md](docs/ADVANCED_ANALYTICS_TECHNIQUES.md)** - Time series, survival analysis, causal inference
- **[ARCHITECTURE_VISION.md](docs/ARCHITECTURE_VISION.md)** - 7-layer system architecture, cloud deployment
- **[TECHNICAL_IMPLEMENTATION.md](docs/TECHNICAL_IMPLEMENTATION.md)** - PostgreSQL, Airflow, FastAPI, MLflow
- **[NLP_TEXT_MINING.md](docs/NLP_TEXT_MINING.md)** - SafeAeroBERT, text preprocessing, topic modeling
- **[FEATURE_ENGINEERING_GUIDE.md](docs/FEATURE_ENGINEERING_GUIDE.md)** - Domain-specific feature creation for ML
- **[MODEL_DEPLOYMENT_GUIDE.md](docs/MODEL_DEPLOYMENT_GUIDE.md)** - MLflow versioning, A/B testing, drift detection
- **[GEOSPATIAL_ADVANCED.md](docs/GEOSPATIAL_ADVANCED.md)** - HDBSCAN clustering, Getis-Ord Gi* hotspot analysis
- **[DOCUMENTATION_COMPLETION_REPORT.md](docs/archive/DOCUMENTATION_COMPLETION_REPORT.md)** - Executive summary of TIER 1 work

### Supporting Documentation (docs/supporting/)

- **[RESEARCH_OPPORTUNITIES.md](docs/supporting/RESEARCH_OPPORTUNITIES.md)** - Academic venues, grant funding, industry partnerships
- **[DATA_QUALITY_STRATEGY.md](docs/supporting/DATA_QUALITY_STRATEGY.md)** - Great Expectations, Pandera validation, MICE imputation
- **[ETHICAL_CONSIDERATIONS.md](docs/supporting/ETHICAL_CONSIDERATIONS.md)** - Bias detection, fairness metrics, responsible AI
- **[VISUALIZATION_DASHBOARDS.md](docs/supporting/VISUALIZATION_DASHBOARDS.md)** - Plotly Dash vs Streamlit, KPI design
- **[API_DESIGN.md](docs/supporting/API_DESIGN.md)** - RESTful API, FastAPI, authentication, rate limiting
- **[PERFORMANCE_OPTIMIZATION.md](docs/supporting/PERFORMANCE_OPTIMIZATION.md)** - Database indexing, Polars vs pandas benchmarks
- **[SECURITY_BEST_PRACTICES.md](docs/supporting/SECURITY_BEST_PRACTICES.md)** - Encryption, RBAC/ABAC, secrets management

### Project Roadmap (to-dos/)

- **[ROADMAP_OVERVIEW.md](to-dos/ROADMAP_OVERVIEW.md)** - 15-month plan (5 phases, Q1 2025 - Q1 2026)
- **[PHASE_1_FOUNDATION.md](to-dos/PHASE_1_FOUNDATION.md)** - Database migration, ETL pipeline, data quality, API (12 weeks, 74KB, 32 code examples)
- **[PHASE_2_ANALYTICS.md](to-dos/PHASE_2_ANALYTICS.md)** - Time series, geospatial, survival analysis, dashboards (12 weeks, 99KB, 30+ code examples)
- **[PHASE_3_MACHINE_LEARNING.md](to-dos/PHASE_3_MACHINE_LEARNING.md)** - Feature engineering, XGBoost, SHAP, MLflow (12 weeks)
- **[PHASE_4_AI_INTEGRATION.md](to-dos/PHASE_4_AI_INTEGRATION.md)** - NLP pipeline, RAG system, knowledge graphs (12 weeks)
- **[PHASE_5_PRODUCTION.md](to-dos/PHASE_5_PRODUCTION.md)** - Kubernetes, public API, real-time capabilities (12 weeks)
- **[TECHNICAL_DEBT.md](to-dos/TECHNICAL_DEBT.md)** - Code quality, refactoring priorities, performance bottlenecks
- **[RESEARCH_TASKS.md](to-dos/RESEARCH_TASKS.md)** - Open research questions, experiments, conference submissions
- **[TESTING_STRATEGY.md](to-dos/TESTING_STRATEGY.md)** - Test pyramid, unit/integration/E2E tests, security testing
- **[DEPLOYMENT_CHECKLIST.md](to-dos/DEPLOYMENT_CHECKLIST.md)** - 100-item production launch checklist

### Key Highlights

- **üéØ 91.2% ML Accuracy**: XGBoost severity prediction benchmark
- **üìä 100+ Features**: Comprehensive feature engineering pipeline
- **ü§ñ 87.9% NLP Accuracy**: SafeAeroBERT for aviation narratives
- **üìà 15-Month Roadmap**: Detailed sprint-level planning
- **üíª 500+ Code Examples**: Production-ready implementations
- **üî¨ 50+ Academic Papers**: Research-backed methodologies

## Recent Improvements

### Error Handling & Data Validation (v1.0.1)

All Python example scripts now include comprehensive error handling and data validation, making them production-ready for real-world NTSB data analysis. Scripts gracefully handle data quality issues and provide clear user feedback.

**Key Fixes**:

1. **Seasonal Analysis Date Parsing** - Fixed crash on invalid date formats
   - **Issue**: Script crashed with "Conversion Error: Could not convert string '/0' to INT32"
   - **Solution**: Implemented TRY_CAST, regex validation, and BETWEEN checks
   - **Result**: Analysis continues gracefully with warning message instead of crashing

2. **Geospatial Coordinate Columns** - Fixed coordinate mapping bug
   - **Issue**: Script found 0 events because it queried DMS format columns (latitude/longitude)
   - **Root Cause**: NTSB database stores coordinates in two formats:
     - DMS format: latitude/longitude (e.g., "043594N", "0883325W")
     - Decimal degrees: dec_latitude/dec_longitude (e.g., 43.98, -88.55)
   - **Solution**: Changed to use dec_latitude/dec_longitude columns
   - **Result**: Now successfully loads 7,903 events and creates 3 interactive maps

3. **Database-Prefixed Filenames** - Fixed CSV file references
   - **Issue**: Scripts looked for generic filenames (events.csv)
   - **Solution**: Updated to use database-prefixed names (avall-events.csv)
   - **Result**: Scripts work out-of-the-box after running extraction scripts

**Error Handling Improvements**:
- Input validation and parameter checking (year ranges, coordinate bounds)
- Defensive SQL queries with TRY_CAST, COALESCE, TRIM, LENGTH validation
- Comprehensive try-except blocks with meaningful error messages
- Empty dataset detection and warning messages
- Graceful degradation (continue analysis when one part fails)
- Formatted output with thousand separators

## Testing Results

All example scripts have been tested and verified:

### quick_analysis.py
- ‚úÖ Analyzes 100 recent events (2023-2024)
- ‚úÖ Reports 250 fatalities, 48 serious injuries
- ‚úÖ Identifies 21 fatal and 79 non-fatal accidents
- ‚úÖ Handles NULL values in injury fields

### advanced_analysis.py
- ‚úÖ Processes 29,773 total events
- ‚úÖ Completes 5 core analyses successfully
- ‚úÖ Handles invalid dates gracefully in seasonal analysis
- ‚úÖ Generates summary report with 9,510 records (2020+)
- ‚úÖ Top aircraft: Cessna 172 (643), Boeing 737 (616)

### geospatial_analysis.py
- ‚úÖ Loads 7,903 events with valid coordinates (2020+)
- ‚úÖ Creates 3 interactive maps (accident map, heatmap, fatal accidents)
- ‚úÖ Maps 1,389 fatal accidents
- ‚úÖ Regional analysis: West (9,442), South (8,142), Midwest (4,339)
- ‚úÖ Uses decimal coordinate columns (dec_latitude/dec_longitude)

## Project Status

**Version**: 2.5.0
**Status**: Production-ready with complete historical coverage, comprehensive analytics, and ML capabilities
**Last Updated**: November 9, 2025
**Phase 1**: ‚úÖ COMPLETE (Infrastructure - Sprints 1-4)
**Phase 2**: ‚úÖ COMPLETE (Analytics - Sprints 1-10)
**Production Ready**: December 1st, 2025 first production run

This repository is fully functional and production-ready with:
- **Complete 64-year historical coverage** (1962-2025, 179,809 events, zero gaps)
- Three comprehensive databases (1962-present, 1.6GB MDB files, all integrated)
- High-performance PostgreSQL database (801 MB, 179,809 events, ~1.3M total rows)
- Query optimization: 6 materialized views, 59 indexes (30-114x speedup)
- Performance: p50 2ms, p95 13ms, p99 47ms, 96.48% buffer cache hit ratio
- Database health: 98/100 score (excellent)
- Code mapping system: 5 tables, 945+ legacy codes decoded
- Monitoring infrastructure: Slack/Email notifications, anomaly detection, 4 monitoring views
- Automated Airflow ETL pipeline with production DAG (8 tasks, 1m 50s baseline)
- Database maintenance automation (10-phase grooming, ~8s execution)
- Automated one-command database setup (no manual SQL required)
- Production-grade ETL with staging tables and duplicate detection
- Data quality: 100% (zero duplicates, zero orphans, 100% FK integrity)
- Comprehensive data validation suite
- Complete extraction and analysis toolkit
- Active maintenance and monthly data updates (avall.mdb)
- Production-ready Python examples with robust error handling

### Sprint 4 Achievements (November 8, 2025)

‚úÖ **Phase 1 Sprint 4: PRE1982 Historical Data Integration** - COMPLETE

**Major Achievement**: Complete 64-year historical coverage (1962-2025)

- **Legacy Data Integration** (87,038 events, 1962-1981)
  - Custom ETL pipeline for denormalized schema transformation
  - Synthetic ev_id generation (YYYYMMDDX{RecNum:06d} format)
  - Wide-to-tall conversion (50+ injury/crew columns ‚Üí normalized rows)
  - 2.78√ó data expansion for proper normalization

- **Code Mapping System** (5 tables, 945+ codes)
  - State codes (56 states/territories)
  - Age group codes (12 categories)
  - Cause/factor codes (861 distinct findings)
  - Damage level codes (5 severity levels)
  - Crew category codes (11 certification types)

- **Database Growth**
  - Events: 92,771 ‚Üí 179,809 (+87,038, +93.7%)
  - Total Rows: ~733K ‚Üí ~1.3M (+564,468, +77%)
  - Database Size: 512 MB ‚Üí 801 MB (+288 MB)
  - Date Coverage: 1977-2025 ‚Üí 1962-2025 (+16 years)

- **Database Maintenance Automation**
  - 10-phase comprehensive grooming script (391 lines)
  - ANALYZE, VACUUM, reindex with deadlock prevention
  - Execution time: ~8 seconds for complete maintenance
  - Health score: 98/100 (excellent)

- **Data Quality**: 100%
  - Zero duplicate events
  - Zero orphaned records
  - 100% foreign key integrity
  - All coordinates validated

- **13 Critical Bug Fixes**
  - INTEGER/TIME/CSV quoting conversions
  - Complex data type handling
  - Schema transformation edge cases

See [Sprint 4 Completion Report](docs/SPRINT_4_COMPLETION_REPORT.md) for comprehensive documentation.

### Phase 2 Achievements (November 9, 2025)

‚úÖ **Phase 2: Comprehensive Analytics Platform** - COMPLETE (Sprints 1-10)

**Major Achievement**: Complete analytics suite from exploratory analysis to production ML models

#### Sprint 1-2: Exploratory Data Analysis & Temporal Trends ‚úÖ
- **4 Jupyter Notebooks** (2,675 lines): EDA, temporal trends, aircraft safety, cause factors
- **20 Publication-Quality Visualizations**: Distribution charts, time series, correlation plots
- **Statistical Rigor**: Chi-square tests, Mann-Whitney U, linear regression, ARIMA forecasting
- **Key Finding**: 31% decline in accidents since 2000 (p < 0.001)

#### Sprint 3-4: REST API Foundation + Geospatial API ‚úÖ
- **21 API Endpoints**: Health, events, statistics, search, geospatial (FastAPI)
- **Production Features**: Connection pooling (20+10), pagination, filtering, full-text search, GeoJSON export
- **Performance**: <100ms response time for most endpoints
- **Documentation**: OpenAPI/Swagger UI at `/docs`

#### Sprint 5: Interactive Streamlit Dashboard ‚úÖ
- **5-Page Dashboard** (2,918 lines): Overview, Temporal, Geographic, Aircraft, Cause Factors
- **25+ Visualizations**: Plotly charts + Folium maps
- **Database Integration**: Connection pooling, query caching (1-hour TTL)
- **Performance**: All pages <2.5s load time
- **Production Ready**: Zero console warnings after SQLAlchemy migration

#### Sprint 6-7: Statistical Modeling & ML Preparation ‚úÖ
- **Logistic Regression**: 78.47% accuracy, ROC-AUC 0.70, PRODUCTION READY
- **Random Forest**: 79.48% accuracy, needs improvement (75% UNKNOWN finding codes)
- **Feature Engineering**: 30 ML-ready features from 92,767 events
- **Model Artifacts**: Saved models (joblib), metadata, visualizations

#### Sprint 8: Advanced Geospatial Analysis ‚úÖ
- **DBSCAN Clustering**: 64 spatial clusters, 98.2% clustering rate
- **KDE Heatmaps**: Event and fatality density surfaces
- **Getis-Ord Gi***: 66 significant hotspots (p < 0.05)
- **Moran's I**: Global autocorrelation 0.0111 (p < 0.001)
- **5 Interactive Maps**: Clusters, heatmaps, hotspots, LISA clusters

#### Sprint 9-10: NLP & Text Mining ‚úÖ
- **5 NLP Methods**: TF-IDF, LDA topic modeling, Word2Vec, NER, sentiment analysis
- **52,880 Narratives** processed with 5 different techniques
- **10 Latent Topics** discovered (LDA coherence 0.42)
- **89,246 Entities** extracted (organizations, locations, aircraft makes)
- **Sentiment-Severity Correlation**: r = -0.45 (p < 0.001)
- **9 Visualizations**: Word clouds, topic distributions, entity charts, sentiment plots

#### Phase 2 Summary
- **Total Deliverables**: 15 notebooks, 6 scripts, 40+ visualizations, 6 reports
- **Production Assets**: Dashboard (5 pages), REST API (21 endpoints), 2 ML models, NLP models
- **Code Quality**: All Python ruff-formatted, comprehensive type hints
- **Documentation**: 6 comprehensive sprint reports (3,000+ lines total)

See sprint completion reports in `reports/` and `docs/` for detailed metrics.

### Sprint 3 Week 3 Achievements (November 7, 2025)

‚úÖ **Monitoring & Observability Infrastructure** - Production-Ready

- **Notification System** (449 lines)
  - Slack webhook integration for real-time alerts (<30s latency)
  - Email SMTP notifications (Gmail App Password support)
  - CRITICAL, WARNING, SUCCESS alert levels with rich formatting
  - Automated alerts for DAG failures and data quality issues

- **Anomaly Detection** (480 lines)
  - 5 automated data quality checks (missing fields, coordinate outliers, statistical anomalies, referential integrity, duplicates)
  - CLI interface with JSON output for integration
  - Exit codes: 0=pass, 1=warning, 2=critical
  - Current status: ‚úÖ All 5 checks passed, 0 anomalies detected

- **Monitoring Views** (323 lines, 4 views)
  - `vw_database_metrics`: Table sizes, row counts, maintenance stats
  - `vw_data_quality_checks`: 9 quality metrics with severity levels
  - `vw_monthly_event_trends`: Event trends (24 months)
  - `vw_database_health`: Overall system health snapshot
  - Query performance: All views <50ms response time

- **Documentation** (2,399 lines total)
  - Comprehensive monitoring setup guide (754 lines)
  - Slack/Email integration instructions
  - Troubleshooting guide (5 common issues + diagnostics)
  - Production readiness checklist

- **Production Status**: ‚úÖ Ready for December 1st, 2025 first production run

See [Sprint 3 Week 3 Completion Report](docs/SPRINT_3_WEEK_3_COMPLETION_REPORT.md) for detailed metrics.

### Sprint 3 Week 2 Achievements (November 7, 2025)

‚úÖ **Production Airflow DAG** - Automated Monthly Updates

- **monthly_sync_dag.py** (1,467 lines, 8 tasks)
  - Automated NTSB data sync (check updates, download, extract, backup, load, validate, refresh MVs, notify)
  - Smart skip logic (only download when file size changes)
  - Baseline run: 1m 50s, 8/8 tasks SUCCESS
  - Scheduled: 1st of month, 2 AM

- **7 Critical Bug Fixes**
  - INTEGER conversion (22 columns, prevents "0.0" errors)
  - TIME conversion (HHMM ‚Üí HH:MM:SS format)
  - Generated columns (dynamic exclusion from INSERT)
  - Qualified column names (table-aliased JOIN references)
  - --force flag support (monthly re-loads with duplicate detection)
  - System catalog compatibility (relname vs tablename)
  - UNIQUE indexes for CONCURRENT materialized view refresh

- **Database Cleanup**
  - Removed 3.2M duplicate records from test loads
  - Database size: 2,759 MB ‚Üí 512 MB (81.4% reduction)
  - All foreign key integrity preserved

See [Sprint 3 Week 2 Completion Report](docs/SPRINT_3_WEEK_2_COMPLETION_REPORT.md) for detailed bug documentation.

### Sprint 2 Achievements (November 2025)

‚úÖ **Query Optimization**
- 6 materialized views (yearly, state, aircraft, decade, crew, findings)
- 59 total indexes (30 base + 29 performance/MV indexes)
- 30-114x speedup for analytical queries
- Index usage: 99.99% on primary tables

‚úÖ **Historical Data Integration**
- 92,771 events loaded (1977-2025, 48 years with gaps)
- Staging table infrastructure for safe ETL operations
- Load tracking system prevents duplicate loads
- Production-grade deduplication logic

‚úÖ **Performance Benchmarks**
- 20 comprehensive benchmark queries across 8 categories
- Query latency: p50 ~2ms, p95 ~13ms, p99 ~47ms
- Buffer cache hit ratio: 98.81% (excellent memory utilization)
- All queries meet or exceed performance targets

‚úÖ **Production Infrastructure**
- `setup_database.sh` - Automated one-command setup (285 lines)
- NO SUDO operations required after initial setup
- Regular user ownership model
- Comprehensive data validation framework

See [Sprint 2 Completion Report](SPRINT_2_COMPLETION_REPORT.md) for detailed metrics.

**Repository Topics**: aviation, ntsb, accident-analysis, aviation-safety, data-analysis, python, fish-shell, mdb-database, duckdb, jupyter-notebook

## Next Steps (Phase 2)

**Current Status**: ‚úÖ Phase 1 Complete - Production-Ready Infrastructure

**Completed Phase 1 Deliverables** (All 4 Sprints):
- ‚úÖ PostgreSQL database with 801 MB, 179,809 events, ~1.3M rows
- ‚úÖ Complete 64-year historical coverage (1962-2025, zero gaps)
- ‚úÖ Automated ETL pipeline with Airflow (8-task production DAG)
- ‚úÖ Database maintenance automation (10-phase grooming, ~8s execution)
- ‚úÖ Code mapping system (5 tables, 945+ legacy codes decoded)
- ‚úÖ Monitoring & observability (Slack/Email, anomaly detection, 4 views)
- ‚úÖ Data quality: 100% (zero duplicates, zero orphans, 100% FK integrity)
- ‚úÖ Query optimization: 6 materialized views, 59 indexes (30-114x speedup)
- ‚úÖ Production-ready: December 1st, 2025 first production run

### Planned Phase 2 Features

**Advanced Analytics** (Priority 1)
- Time series analysis with ARIMA, Prophet, LSTM (85%+ accuracy target)
- Geospatial hotspot detection with HDBSCAN clustering
- Survival analysis with Cox Proportional Hazards models
- Interactive Streamlit dashboard with real-time metrics
- Monthly trend analysis and forecasting

**Machine Learning Preparation** (Priority 2)
- Feature engineering pipeline (100+ features)
- Severity prediction models (XGBoost 90%+ accuracy target)
- SHAP explainability for model interpretation
- MLflow model versioning and serving
- Automated model retraining pipeline

**Estimated Timeline**: 12 weeks (December 2025 - February 2026)

**Note**: PRE1982.MDB historical data integration originally planned for Phase 2 was completed ahead of schedule in Sprint 4.

See [Phase 2 Analytics Plan](to-dos/PHASE_2_ANALYTICS.md) for detailed implementation roadmap.

## Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

Ways to contribute:
- Add analysis scripts and Jupyter notebooks
- Improve data cleaning/preprocessing utilities
- Create visualization dashboards
- Enhance documentation
- Report bugs and suggest features
- Share your research using this dataset

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**Note**: The NTSB aviation accident data itself is in the public domain as U.S. government data. The scripts, documentation, and tooling in this repository are provided under the MIT License.

## Acknowledgments

- **National Transportation Safety Board (NTSB)** for maintaining and providing comprehensive aviation accident investigation data
- **mdbtools** project for enabling MDB file access on Linux/Unix systems
- **DuckDB** project for fast analytical SQL queries
- All contributors who have improved this repository

## Resources

- [NTSB Aviation Accident Database](https://www.ntsb.gov/Pages/AviationQueryV2.aspx)
- [NTSB Coding Manual](https://www.ntsb.gov/_layouts/ntsb.aviation/codeman.pdf)
- [FAA Aircraft Registry](https://www.faa.gov/licenses_certificates/aircraft_certification/aircraft_registry/)
- [Aviation Safety Network](https://aviation-safety.net/)
